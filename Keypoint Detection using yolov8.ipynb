{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8711eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\BAPS\\Documents\\Pose_estimation\\bus.jpg: 320x256 3 persons, 79.8ms\n",
      "Speed: 2.3ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 256)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Keypoints object with attributes:\n",
      "\n",
      "conf: tensor([[0.9357, 0.8155, 0.9203, 0.4098, 0.8064, 0.9807, 0.9922, 0.8838, 0.9657, 0.8556, 0.9366, 0.9929, 0.9956, 0.9882, 0.9922, 0.9746, 0.9814],\n",
      "        [0.9300, 0.8164, 0.9077, 0.4558, 0.7937, 0.9757, 0.9889, 0.8038, 0.9283, 0.7636, 0.8796, 0.9762, 0.9849, 0.9375, 0.9577, 0.8713, 0.9022],\n",
      "        [0.1472, 0.0858, 0.1331, 0.0944, 0.2145, 0.2744, 0.5000, 0.1173, 0.3841, 0.1289, 0.3151, 0.4687, 0.6101, 0.5478, 0.6756, 0.5594, 0.6617]])\n",
      "data: tensor([[[1.3730e+02, 4.4015e+02, 9.3570e-01],\n",
      "         [1.4473e+02, 4.3049e+02, 8.1547e-01],\n",
      "         [1.2671e+02, 4.3045e+02, 9.2031e-01],\n",
      "         [1.5494e+02, 4.3738e+02, 4.0980e-01],\n",
      "         [1.0435e+02, 4.3613e+02, 8.0638e-01],\n",
      "         [1.6064e+02, 4.9238e+02, 9.8066e-01],\n",
      "         [8.5309e+01, 4.9328e+02, 9.9217e-01],\n",
      "         [1.7525e+02, 5.5844e+02, 8.8383e-01],\n",
      "         [9.4905e+01, 5.6424e+02, 9.6571e-01],\n",
      "         [1.6426e+02, 5.4990e+02, 8.5563e-01],\n",
      "         [1.5234e+02, 5.4940e+02, 9.3657e-01],\n",
      "         [1.5501e+02, 6.4159e+02, 9.9292e-01],\n",
      "         [9.8959e+01, 6.4418e+02, 9.9562e-01],\n",
      "         [1.7517e+02, 7.5315e+02, 9.8821e-01],\n",
      "         [8.8101e+01, 7.5568e+02, 9.9224e-01],\n",
      "         [1.8883e+02, 8.5308e+02, 9.7456e-01],\n",
      "         [7.3294e+01, 8.5646e+02, 9.8142e-01]],\n",
      "\n",
      "        [[2.9222e+02, 4.4732e+02, 9.3002e-01],\n",
      "         [2.9899e+02, 4.3926e+02, 8.1641e-01],\n",
      "         [2.8335e+02, 4.3837e+02, 9.0769e-01],\n",
      "         [3.0655e+02, 4.4483e+02, 4.5580e-01],\n",
      "         [2.6447e+02, 4.4196e+02, 7.9367e-01],\n",
      "         [3.1086e+02, 4.9023e+02, 9.7571e-01],\n",
      "         [2.4958e+02, 4.9103e+02, 9.8887e-01],\n",
      "         [3.3264e+02, 5.2833e+02, 8.0384e-01],\n",
      "         [2.4746e+02, 5.3815e+02, 9.2827e-01],\n",
      "         [3.1458e+02, 5.0135e+02, 7.6357e-01],\n",
      "         [2.8013e+02, 5.1700e+02, 8.7957e-01],\n",
      "         [2.9956e+02, 6.2213e+02, 9.7621e-01],\n",
      "         [2.5913e+02, 6.2383e+02, 9.8485e-01],\n",
      "         [2.9341e+02, 7.2507e+02, 9.3746e-01],\n",
      "         [2.6829e+02, 7.2748e+02, 9.5767e-01],\n",
      "         [2.7869e+02, 8.2048e+02, 8.7131e-01],\n",
      "         [2.5887e+02, 8.2413e+02, 9.0223e-01]],\n",
      "\n",
      "        [[7.9767e+02, 4.3310e+02, 1.4725e-01],\n",
      "         [8.0199e+02, 4.2207e+02, 8.5770e-02],\n",
      "         [7.9461e+02, 4.2247e+02, 1.3313e-01],\n",
      "         [8.0087e+02, 4.2511e+02, 9.4389e-02],\n",
      "         [7.9898e+02, 4.2691e+02, 2.1448e-01],\n",
      "         [7.9691e+02, 4.7951e+02, 2.7437e-01],\n",
      "         [7.9371e+02, 4.8184e+02, 4.9997e-01],\n",
      "         [7.7971e+02, 5.5309e+02, 1.1730e-01],\n",
      "         [7.7845e+02, 5.5430e+02, 3.8409e-01],\n",
      "         [7.7411e+02, 5.9464e+02, 1.2886e-01],\n",
      "         [7.7593e+02, 5.9442e+02, 3.1513e-01],\n",
      "         [7.8451e+02, 6.1740e+02, 4.6870e-01],\n",
      "         [7.8397e+02, 6.1783e+02, 6.1006e-01],\n",
      "         [7.7263e+02, 7.2837e+02, 5.4782e-01],\n",
      "         [7.7248e+02, 7.2868e+02, 6.7564e-01],\n",
      "         [7.3061e+02, 8.3234e+02, 5.5937e-01],\n",
      "         [7.2550e+02, 8.3343e+02, 6.6168e-01]]])\n",
      "has_visible: True\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([3, 17, 3])\n",
      "xy: tensor([[[137.3018, 440.1539],\n",
      "         [144.7262, 430.4870],\n",
      "         [126.7135, 430.4523],\n",
      "         [154.9385, 437.3828],\n",
      "         [104.3500, 436.1287],\n",
      "         [160.6352, 492.3806],\n",
      "         [ 85.3094, 493.2794],\n",
      "         [175.2477, 558.4418],\n",
      "         [ 94.9045, 564.2435],\n",
      "         [164.2583, 549.8994],\n",
      "         [152.3412, 549.3998],\n",
      "         [155.0117, 641.5862],\n",
      "         [ 98.9587, 644.1845],\n",
      "         [175.1748, 753.1459],\n",
      "         [ 88.1009, 755.6782],\n",
      "         [188.8313, 853.0801],\n",
      "         [ 73.2939, 856.4614]],\n",
      "\n",
      "        [[292.2208, 447.3182],\n",
      "         [298.9906, 439.2575],\n",
      "         [283.3482, 438.3732],\n",
      "         [306.5499, 444.8288],\n",
      "         [264.4674, 441.9593],\n",
      "         [310.8594, 490.2285],\n",
      "         [249.5840, 491.0252],\n",
      "         [332.6417, 528.3336],\n",
      "         [247.4638, 538.1464],\n",
      "         [314.5809, 501.3525],\n",
      "         [280.1339, 516.9993],\n",
      "         [299.5551, 622.1343],\n",
      "         [259.1264, 623.8320],\n",
      "         [293.4126, 725.0714],\n",
      "         [268.2852, 727.4758],\n",
      "         [278.6909, 820.4760],\n",
      "         [258.8747, 824.1316]],\n",
      "\n",
      "        [[797.6727, 433.0963],\n",
      "         [801.9875, 422.0748],\n",
      "         [794.6117, 422.4745],\n",
      "         [800.8745, 425.1129],\n",
      "         [798.9825, 426.9076],\n",
      "         [796.9083, 479.5105],\n",
      "         [793.7150, 481.8446],\n",
      "         [779.7128, 553.0929],\n",
      "         [778.4499, 554.2997],\n",
      "         [774.1141, 594.6396],\n",
      "         [775.9330, 594.4219],\n",
      "         [784.5057, 617.4026],\n",
      "         [783.9686, 617.8335],\n",
      "         [772.6268, 728.3680],\n",
      "         [772.4760, 728.6816],\n",
      "         [730.6088, 832.3432],\n",
      "         [725.5008, 833.4283]]])\n",
      "xyn: tensor([[[0.1695, 0.4075],\n",
      "         [0.1787, 0.3986],\n",
      "         [0.1564, 0.3986],\n",
      "         [0.1913, 0.4050],\n",
      "         [0.1288, 0.4038],\n",
      "         [0.1983, 0.4559],\n",
      "         [0.1053, 0.4567],\n",
      "         [0.2164, 0.5171],\n",
      "         [0.1172, 0.5224],\n",
      "         [0.2028, 0.5092],\n",
      "         [0.1881, 0.5087],\n",
      "         [0.1914, 0.5941],\n",
      "         [0.1222, 0.5965],\n",
      "         [0.2163, 0.6974],\n",
      "         [0.1088, 0.6997],\n",
      "         [0.2331, 0.7899],\n",
      "         [0.0905, 0.7930]],\n",
      "\n",
      "        [[0.3608, 0.4142],\n",
      "         [0.3691, 0.4067],\n",
      "         [0.3498, 0.4059],\n",
      "         [0.3785, 0.4119],\n",
      "         [0.3265, 0.4092],\n",
      "         [0.3838, 0.4539],\n",
      "         [0.3081, 0.4547],\n",
      "         [0.4107, 0.4892],\n",
      "         [0.3055, 0.4983],\n",
      "         [0.3884, 0.4642],\n",
      "         [0.3458, 0.4787],\n",
      "         [0.3698, 0.5761],\n",
      "         [0.3199, 0.5776],\n",
      "         [0.3622, 0.6714],\n",
      "         [0.3312, 0.6736],\n",
      "         [0.3441, 0.7597],\n",
      "         [0.3196, 0.7631]],\n",
      "\n",
      "        [[0.9848, 0.4010],\n",
      "         [0.9901, 0.3908],\n",
      "         [0.9810, 0.3912],\n",
      "         [0.9887, 0.3936],\n",
      "         [0.9864, 0.3953],\n",
      "         [0.9838, 0.4440],\n",
      "         [0.9799, 0.4462],\n",
      "         [0.9626, 0.5121],\n",
      "         [0.9610, 0.5132],\n",
      "         [0.9557, 0.5506],\n",
      "         [0.9579, 0.5504],\n",
      "         [0.9685, 0.5717],\n",
      "         [0.9679, 0.5721],\n",
      "         [0.9539, 0.6744],\n",
      "         [0.9537, 0.6747],\n",
      "         [0.9020, 0.7707],\n",
      "         [0.8957, 0.7717]]])\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Predict with the model\n",
    "# results = model('https://ultralytics.com/images/bus.jpg') \n",
    "\n",
    "source = 'https://ultralytics.com/images/bus.jpg'\n",
    "results = model.predict(source, save=True, imgsz=320, conf=0.5)\n",
    "\n",
    "# View results\n",
    "for r in results:\n",
    "    print(r.keypoints)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16edf7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061dea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    WARNING  stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Example:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 87.8ms\n",
      "video 1/1 (2/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 57.9ms\n",
      "video 1/1 (3/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 77.3ms\n",
      "video 1/1 (4/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 42.6ms\n",
      "video 1/1 (5/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 48.2ms\n",
      "video 1/1 (6/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 75.5ms\n",
      "video 1/1 (7/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.1ms\n",
      "video 1/1 (8/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 33.8ms\n",
      "video 1/1 (9/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 95.7ms\n",
      "video 1/1 (10/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 89.5ms\n",
      "video 1/1 (11/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 40.8ms\n",
      "video 1/1 (12/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 68.6ms\n",
      "video 1/1 (13/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 79.1ms\n",
      "video 1/1 (14/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 63.3ms\n",
      "video 1/1 (15/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 43.5ms\n",
      "video 1/1 (16/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 58.1ms\n",
      "video 1/1 (17/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.6ms\n",
      "video 1/1 (18/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 39.7ms\n",
      "video 1/1 (19/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 65.0ms\n",
      "video 1/1 (20/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 57.8ms\n",
      "video 1/1 (21/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 59.2ms\n",
      "video 1/1 (22/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.5ms\n",
      "video 1/1 (23/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 56.3ms\n",
      "video 1/1 (24/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 28.8ms\n",
      "video 1/1 (25/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 56.1ms\n",
      "video 1/1 (26/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 50.3ms\n",
      "video 1/1 (27/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 45.7ms\n",
      "video 1/1 (28/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 40.9ms\n",
      "video 1/1 (29/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 52.1ms\n",
      "video 1/1 (30/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 107.3ms\n",
      "video 1/1 (31/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 97.7ms\n",
      "video 1/1 (32/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 48.7ms\n",
      "video 1/1 (33/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 49.2ms\n",
      "video 1/1 (34/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 42.2ms\n",
      "video 1/1 (35/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.7ms\n",
      "video 1/1 (36/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 65.3ms\n",
      "video 1/1 (37/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 30.0ms\n",
      "video 1/1 (38/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 74.2ms\n",
      "video 1/1 (39/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 56.3ms\n",
      "video 1/1 (40/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 60.4ms\n",
      "video 1/1 (41/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 64.2ms\n",
      "video 1/1 (42/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 65.6ms\n",
      "video 1/1 (43/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 98.8ms\n",
      "video 1/1 (44/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.8ms\n",
      "video 1/1 (45/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 54.4ms\n",
      "video 1/1 (46/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 38.9ms\n",
      "video 1/1 (47/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 38.0ms\n",
      "video 1/1 (48/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 49.2ms\n",
      "video 1/1 (49/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 50.0ms\n",
      "video 1/1 (50/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 115.9ms\n",
      "video 1/1 (51/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 97.1ms\n",
      "video 1/1 (52/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 90.7ms\n",
      "video 1/1 (53/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 60.3ms\n",
      "video 1/1 (54/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 49.1ms\n",
      "video 1/1 (55/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.7ms\n",
      "video 1/1 (56/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 128.0ms\n",
      "video 1/1 (57/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 89.0ms\n",
      "video 1/1 (58/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.4ms\n",
      "video 1/1 (59/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 50.8ms\n",
      "video 1/1 (60/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 55.0ms\n",
      "video 1/1 (61/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 59.4ms\n",
      "video 1/1 (62/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.2ms\n",
      "video 1/1 (63/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (64/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 42.3ms\n",
      "video 1/1 (65/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 71.3ms\n",
      "video 1/1 (66/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 53.9ms\n",
      "video 1/1 (67/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 40.2ms\n",
      "video 1/1 (68/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 81.6ms\n",
      "video 1/1 (69/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 63.8ms\n",
      "video 1/1 (70/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 56.3ms\n",
      "video 1/1 (71/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 76.0ms\n",
      "video 1/1 (72/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.4ms\n",
      "video 1/1 (73/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 67.1ms\n",
      "video 1/1 (74/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 45.7ms\n",
      "video 1/1 (75/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.9ms\n",
      "video 1/1 (76/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 90.3ms\n",
      "video 1/1 (77/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 70.9ms\n",
      "video 1/1 (78/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 94.3ms\n",
      "video 1/1 (79/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 125.3ms\n",
      "video 1/1 (80/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 183.5ms\n",
      "video 1/1 (81/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 114.2ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (82/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.9ms\n",
      "video 1/1 (83/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 63.9ms\n",
      "video 1/1 (84/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 78.4ms\n",
      "video 1/1 (85/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 81.9ms\n",
      "video 1/1 (86/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 57.3ms\n",
      "video 1/1 (87/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 55.8ms\n",
      "video 1/1 (88/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 74.2ms\n",
      "video 1/1 (89/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.3ms\n",
      "video 1/1 (90/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 42.1ms\n",
      "video 1/1 (91/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.5ms\n",
      "video 1/1 (92/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.7ms\n",
      "video 1/1 (93/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 60.4ms\n",
      "video 1/1 (94/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 59.9ms\n",
      "video 1/1 (95/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 66.6ms\n",
      "video 1/1 (96/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 53.9ms\n",
      "video 1/1 (97/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 49.9ms\n",
      "video 1/1 (98/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 61.9ms\n",
      "video 1/1 (99/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 41.3ms\n",
      "video 1/1 (100/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 46.9ms\n",
      "video 1/1 (101/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 77.8ms\n",
      "video 1/1 (102/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 2 persons, 31.3ms\n",
      "video 1/1 (103/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (104/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (105/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.4ms\n",
      "video 1/1 (106/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (107/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (108/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (109/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.7ms\n",
      "video 1/1 (110/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 73.6ms\n",
      "video 1/1 (111/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 71.4ms\n",
      "video 1/1 (112/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (113/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 43.9ms\n",
      "video 1/1 (114/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 66.4ms\n",
      "video 1/1 (115/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 38.0ms\n",
      "video 1/1 (116/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (117/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 61.3ms\n",
      "video 1/1 (118/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (119/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (120/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.3ms\n",
      "video 1/1 (121/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (122/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (123/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (124/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.0ms\n",
      "video 1/1 (125/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 43.4ms\n",
      "video 1/1 (126/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 61.4ms\n",
      "video 1/1 (127/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (128/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (129/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (130/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 109.2ms\n",
      "video 1/1 (131/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 43.3ms\n",
      "video 1/1 (132/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (133/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 67.5ms\n",
      "video 1/1 (134/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (135/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (136/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 62.5ms\n",
      "video 1/1 (137/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 73.6ms\n",
      "video 1/1 (138/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 136.5ms\n",
      "video 1/1 (139/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 50.2ms\n",
      "video 1/1 (140/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 74.7ms\n",
      "video 1/1 (141/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 73.0ms\n",
      "video 1/1 (142/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.8ms\n",
      "video 1/1 (143/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 55.9ms\n",
      "video 1/1 (144/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.3ms\n",
      "video 1/1 (145/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 48.4ms\n",
      "video 1/1 (146/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 134.1ms\n",
      "video 1/1 (147/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 76.3ms\n",
      "video 1/1 (148/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 30.4ms\n",
      "video 1/1 (149/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 44.1ms\n",
      "video 1/1 (150/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "video 1/1 (151/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.4ms\n",
      "video 1/1 (152/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 97.2ms\n",
      "video 1/1 (153/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 47.8ms\n",
      "video 1/1 (154/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 49.0ms\n",
      "video 1/1 (155/155) C:\\Users\\BAPS\\Documents\\Pose_estimation\\dance.mp4: 192x320 1 person, 46.9ms\n",
      "Speed: 1.6ms preprocess, 62.0ms inference, 2.5ms postprocess per image at shape (1, 3, 192, 320)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [157, 141, 126],\n",
       "         [157, 141, 126],\n",
       "         [158, 142, 127]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [157, 141, 126],\n",
       "         [158, 142, 127],\n",
       "         [158, 142, 127]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [158, 142, 127],\n",
       "         [158, 142, 127],\n",
       "         [158, 142, 127]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  92,  81],\n",
       "         [125,  94,  83],\n",
       "         [127,  96,  85],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[131, 100,  89],\n",
       "         [131, 100,  89],\n",
       "         [131, 100,  89],\n",
       "         ...,\n",
       "         [119,  94,  85],\n",
       "         [119,  94,  85],\n",
       "         [119,  94,  85]],\n",
       " \n",
       "        [[139, 108,  97],\n",
       "         [137, 106,  95],\n",
       "         [132, 101,  90],\n",
       "         ...,\n",
       "         [118,  93,  84],\n",
       "         [118,  93,  84],\n",
       "         [119,  94,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 87.78047561645508, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 156, 141],\n",
       "         [172, 156, 141],\n",
       "         [172, 156, 141],\n",
       "         ...,\n",
       "         [162, 144, 129],\n",
       "         [162, 144, 129],\n",
       "         [162, 144, 129]],\n",
       " \n",
       "        [[172, 156, 141],\n",
       "         [171, 155, 140],\n",
       "         [171, 155, 140],\n",
       "         ...,\n",
       "         [163, 145, 130],\n",
       "         [163, 145, 130],\n",
       "         [163, 145, 130]],\n",
       " \n",
       "        [[172, 156, 141],\n",
       "         [171, 155, 140],\n",
       "         [171, 155, 140],\n",
       "         ...,\n",
       "         [161, 145, 130],\n",
       "         [161, 145, 130],\n",
       "         [161, 145, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[121,  92,  81],\n",
       "         [117,  88,  77],\n",
       "         [115,  86,  75],\n",
       "         ...,\n",
       "         [115,  92,  83],\n",
       "         [115,  92,  83],\n",
       "         [115,  92,  83]],\n",
       " \n",
       "        [[123,  94,  83],\n",
       "         [119,  90,  79],\n",
       "         [117,  88,  77],\n",
       "         ...,\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84]],\n",
       " \n",
       "        [[124,  95,  84],\n",
       "         [121,  92,  81],\n",
       "         [118,  89,  78],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0037422180175781, 'inference': 57.94215202331543, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 156, 141],\n",
       "         [172, 156, 141],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137]],\n",
       " \n",
       "        [[171, 155, 140],\n",
       "         [171, 155, 140],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137]],\n",
       " \n",
       "        [[172, 156, 141],\n",
       "         [172, 156, 141],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[120,  92,  84],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[120,  92,  84],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[120,  92,  84],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.9600391387939453, 'inference': 77.31270790100098, 'postprocess': 0.9999275207519531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 12.51077651977539, 'inference': 42.634010314941406, 'postprocess': 1.9998550415039062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87]],\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87]],\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.005338668823242, 'inference': 48.21348190307617, 'postprocess': 12.522697448730469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [166, 154, 140],\n",
       "         [165, 153, 139]],\n",
       " \n",
       "        [[175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         [172, 155, 142],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [167, 155, 141],\n",
       "         [166, 154, 140]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [172, 155, 142],\n",
       "         [172, 155, 142],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122,  94,  86],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  89],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[122,  94,  86],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  89],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[122,  94,  86],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  89],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.001119613647461, 'inference': 75.53648948669434, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [175, 159, 144],\n",
       "         ...,\n",
       "         [165, 153, 139],\n",
       "         [164, 152, 138],\n",
       "         [164, 152, 138]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [175, 159, 144],\n",
       "         ...,\n",
       "         [166, 154, 140],\n",
       "         [165, 153, 139],\n",
       "         [165, 153, 139]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [175, 159, 144],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[125,  96,  85],\n",
       "         [126,  97,  86],\n",
       "         [126,  96,  88],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [124,  97,  86],\n",
       "         [124,  96,  88],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [124,  97,  86],\n",
       "         [124,  96,  88],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.9996166229248047, 'inference': 47.0583438873291, 'postprocess': 1.0089874267578125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137],\n",
       "         [161, 149, 135]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [166, 154, 140],\n",
       "         [166, 154, 140],\n",
       "         [166, 154, 140]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [126,  98,  90],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]],\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [126,  98,  90],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]],\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [126,  98,  90],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.9982585906982422, 'inference': 33.76197814941406, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]],\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]],\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85],\n",
       "         [117,  94,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0008811950683594, 'inference': 95.68166732788086, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         ...,\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84]],\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         ...,\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84]],\n",
       " \n",
       "        [[123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         ...,\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84],\n",
       "         [116,  93,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.2249221801757812, 'inference': 89.4930362701416, 'postprocess': 4.567146301269531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[125,  96,  85],\n",
       "         [126,  97,  86],\n",
       "         [126,  97,  86],\n",
       "         ...,\n",
       "         [115,  92,  85],\n",
       "         [115,  92,  85],\n",
       "         [116,  93,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [126,  97,  86],\n",
       "         ...,\n",
       "         [115,  92,  85],\n",
       "         [115,  92,  85],\n",
       "         [116,  93,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [122,  95,  84],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [115,  92,  85],\n",
       "         [115,  92,  85],\n",
       "         [116,  93,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.8663406372070312, 'inference': 40.7717227935791, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [178, 166, 152],\n",
       "         [178, 166, 152],\n",
       "         [178, 166, 152]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [178, 166, 152],\n",
       "         [178, 166, 152],\n",
       "         [178, 166, 152]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [113,  90,  83],\n",
       "         [113,  90,  83],\n",
       "         [113,  90,  83]],\n",
       " \n",
       "        [[124,  97,  86],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         ...,\n",
       "         [111,  88,  81],\n",
       "         [111,  88,  81],\n",
       "         [111,  88,  81]],\n",
       " \n",
       "        [[124,  97,  86],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [110,  87,  80],\n",
       "         [110,  87,  80],\n",
       "         [110,  87,  80]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 5.024909973144531, 'inference': 68.56060028076172, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [111,  88,  81],\n",
       "         [111,  88,  81],\n",
       "         [113,  90,  83]],\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [111,  88,  81],\n",
       "         [111,  88,  81],\n",
       "         [113,  90,  83]],\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [111,  88,  81],\n",
       "         [111,  88,  81],\n",
       "         [113,  90,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 79.1161060333252, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         [174, 158, 143],\n",
       "         ...,\n",
       "         [184, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109,  82,  71],\n",
       "         [112,  85,  74],\n",
       "         [116,  89,  78],\n",
       "         ...,\n",
       "         [111,  88,  81],\n",
       "         [114,  89,  80],\n",
       "         [113,  88,  79]],\n",
       " \n",
       "        [[111,  84,  73],\n",
       "         [113,  86,  75],\n",
       "         [117,  90,  79],\n",
       "         ...,\n",
       "         [113,  90,  83],\n",
       "         [114,  89,  80],\n",
       "         [114,  89,  80]],\n",
       " \n",
       "        [[111,  84,  73],\n",
       "         [113,  86,  75],\n",
       "         [117,  90,  79],\n",
       "         ...,\n",
       "         [113,  90,  83],\n",
       "         [115,  90,  81],\n",
       "         [113,  88,  79]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.004934310913086, 'inference': 63.314199447631836, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         [171, 154, 141],\n",
       "         ...,\n",
       "         [181, 163, 148],\n",
       "         [184, 166, 151],\n",
       "         [185, 167, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[121,  91,  78],\n",
       "         [123,  93,  80],\n",
       "         [125,  95,  82],\n",
       "         ...,\n",
       "         [115,  90,  83],\n",
       "         [113,  88,  81],\n",
       "         [112,  87,  80]],\n",
       " \n",
       "        [[120,  90,  77],\n",
       "         [119,  89,  76],\n",
       "         [119,  89,  76],\n",
       "         ...,\n",
       "         [115,  90,  83],\n",
       "         [114,  89,  82],\n",
       "         [114,  89,  82]],\n",
       " \n",
       "        [[123,  93,  80],\n",
       "         [121,  91,  78],\n",
       "         [119,  89,  76],\n",
       "         ...,\n",
       "         [115,  90,  83],\n",
       "         [115,  90,  83],\n",
       "         [114,  89,  82]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0020732879638672, 'inference': 43.501853942871094, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [177, 167, 153],\n",
       "         [177, 167, 153],\n",
       "         [177, 167, 153]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [178, 168, 154],\n",
       "         [178, 168, 154],\n",
       "         [178, 168, 154]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [178, 168, 154],\n",
       "         [178, 168, 154],\n",
       "         [178, 168, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 109,  98],\n",
       "         [135, 108,  97],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [112,  87,  80],\n",
       "         [113,  88,  81],\n",
       "         [113,  88,  81]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [131, 104,  93],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [115,  90,  83],\n",
       "         [115,  90,  83],\n",
       "         [115,  90,  83]],\n",
       " \n",
       "        [[127, 100,  89],\n",
       "         [126,  99,  88],\n",
       "         [124,  95,  84],\n",
       "         ...,\n",
       "         [118,  93,  86],\n",
       "         [117,  92,  85],\n",
       "         [117,  92,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.0041465759277344, 'inference': 58.127641677856445, 'postprocess': 0.9989738464355469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [178, 167, 151],\n",
       "         [175, 166, 150],\n",
       "         [177, 168, 152]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [181, 170, 154],\n",
       "         [177, 168, 152],\n",
       "         [177, 168, 152]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [181, 170, 154],\n",
       "         [178, 169, 153],\n",
       "         [178, 169, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[118,  89,  78],\n",
       "         [118,  89,  78],\n",
       "         [118,  89,  78],\n",
       "         ...,\n",
       "         [118,  93,  84],\n",
       "         [115,  90,  81],\n",
       "         [112,  87,  78]],\n",
       " \n",
       "        [[120,  93,  82],\n",
       "         [120,  93,  82],\n",
       "         [120,  93,  82],\n",
       "         ...,\n",
       "         [114,  89,  80],\n",
       "         [115,  90,  81],\n",
       "         [113,  88,  79]],\n",
       " \n",
       "        [[126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         ...,\n",
       "         [110,  85,  76],\n",
       "         [114,  89,  80],\n",
       "         [115,  90,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.005338668823242, 'inference': 44.55900192260742, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[181, 164, 151],\n",
       "         [181, 164, 151],\n",
       "         [181, 164, 151],\n",
       "         ...,\n",
       "         [178, 167, 151],\n",
       "         [178, 167, 151],\n",
       "         [177, 166, 150]],\n",
       " \n",
       "        [[179, 162, 149],\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149],\n",
       "         ...,\n",
       "         [178, 167, 151],\n",
       "         [178, 167, 151],\n",
       "         [179, 168, 152]],\n",
       " \n",
       "        [[178, 161, 148],\n",
       "         [178, 161, 148],\n",
       "         [178, 161, 148],\n",
       "         ...,\n",
       "         [178, 167, 151],\n",
       "         [179, 168, 152],\n",
       "         [181, 170, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[124,  92,  84],\n",
       "         [124,  92,  84],\n",
       "         [124,  92,  84],\n",
       "         ...,\n",
       "         [110,  85,  76],\n",
       "         [114,  89,  80],\n",
       "         [118,  93,  84]],\n",
       " \n",
       "        [[118,  88,  80],\n",
       "         [118,  88,  80],\n",
       "         [118,  88,  80],\n",
       "         ...,\n",
       "         [106,  81,  72],\n",
       "         [110,  85,  76],\n",
       "         [113,  88,  79]],\n",
       " \n",
       "        [[122,  92,  84],\n",
       "         [122,  92,  84],\n",
       "         [122,  92,  84],\n",
       "         ...,\n",
       "         [107,  82,  73],\n",
       "         [106,  81,  72],\n",
       "         [109,  84,  75]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0006427764892578, 'inference': 39.69144821166992, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 161, 151],\n",
       "         [177, 161, 151],\n",
       "         [177, 161, 151]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 161, 151],\n",
       "         [177, 161, 151],\n",
       "         [177, 161, 151]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 161, 151],\n",
       "         [177, 161, 151],\n",
       "         [177, 161, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128,  97,  86],\n",
       "         [128,  97,  86],\n",
       "         [128,  97,  86],\n",
       "         ...,\n",
       "         [107,  82,  75],\n",
       "         [107,  82,  75],\n",
       "         [106,  81,  74]],\n",
       " \n",
       "        [[121,  92,  81],\n",
       "         [121,  92,  81],\n",
       "         [121,  92,  81],\n",
       "         ...,\n",
       "         [113,  88,  81],\n",
       "         [112,  87,  80],\n",
       "         [106,  81,  74]],\n",
       " \n",
       "        [[121,  92,  81],\n",
       "         [121,  92,  81],\n",
       "         [121,  92,  81],\n",
       "         ...,\n",
       "         [113,  88,  81],\n",
       "         [113,  88,  81],\n",
       "         [111,  86,  79]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0013580322265625, 'inference': 65.01626968383789, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [177, 163, 148]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [177, 163, 148]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [177, 163, 148]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[137, 105,  97],\n",
       "         [137, 105,  97],\n",
       "         [137, 105,  97],\n",
       "         ...,\n",
       "         [118,  93,  84],\n",
       "         [117,  92,  83],\n",
       "         [114,  89,  80]],\n",
       " \n",
       "        [[141, 110,  99],\n",
       "         [141, 110,  99],\n",
       "         [141, 110,  99],\n",
       "         ...,\n",
       "         [119,  94,  85],\n",
       "         [115,  90,  81],\n",
       "         [112,  87,  78]],\n",
       " \n",
       "        [[139, 108,  97],\n",
       "         [138, 107,  96],\n",
       "         [138, 107,  96],\n",
       "         ...,\n",
       "         [118,  93,  84],\n",
       "         [115,  90,  81],\n",
       "         [113,  88,  79]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.9958744049072266, 'inference': 57.769060134887695, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 164, 146],\n",
       "         [177, 164, 146],\n",
       "         [177, 164, 146]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [177, 164, 146],\n",
       "         [177, 164, 146],\n",
       "         [177, 164, 146]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [176, 163, 145],\n",
       "         [177, 164, 146],\n",
       "         [176, 163, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [113,  94,  81],\n",
       "         [115,  94,  80],\n",
       "         [115,  94,  80]],\n",
       " \n",
       "        [[139, 108,  97],\n",
       "         [139, 108,  97],\n",
       "         [139, 108,  97],\n",
       "         ...,\n",
       "         [114,  95,  82],\n",
       "         [116,  95,  81],\n",
       "         [115,  94,  80]],\n",
       " \n",
       "        [[144, 113, 102],\n",
       "         [144, 113, 102],\n",
       "         [144, 113, 102],\n",
       "         ...,\n",
       "         [114,  95,  82],\n",
       "         [116,  95,  81],\n",
       "         [115,  94,  80]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0006427764892578, 'inference': 59.20290946960449, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [173, 160, 142],\n",
       "         [174, 161, 143],\n",
       "         [175, 162, 144]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [170, 157, 139],\n",
       "         [172, 159, 141],\n",
       "         [172, 159, 141]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [169, 156, 138],\n",
       "         [169, 156, 138],\n",
       "         [169, 156, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[137, 108,  97],\n",
       "         [138, 109,  98],\n",
       "         [139, 110,  99],\n",
       "         ...,\n",
       "         [117,  95,  83],\n",
       "         [114,  95,  82],\n",
       "         [114,  95,  82]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [117,  95,  83],\n",
       "         [114,  95,  82],\n",
       "         [114,  95,  82]],\n",
       " \n",
       "        [[125,  96,  85],\n",
       "         [124,  95,  84],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [117,  95,  83],\n",
       "         [114,  95,  82],\n",
       "         [114,  95,  82]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.9999275207519531, 'inference': 47.464609146118164, 'postprocess': 15.630722045898438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [167, 154, 136],\n",
       "         [168, 153, 135],\n",
       "         [169, 154, 136]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [165, 152, 134],\n",
       "         [165, 150, 132],\n",
       "         [167, 152, 134]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [165, 150, 132],\n",
       "         [167, 151, 136],\n",
       "         [163, 147, 132]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 107,  96],\n",
       "         [136, 107,  96],\n",
       "         [138, 109,  98],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[126,  97,  86],\n",
       "         [126,  97,  86],\n",
       "         [126,  97,  86],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]],\n",
       " \n",
       "        [[125,  96,  85],\n",
       "         [125,  96,  85],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0013580322265625, 'inference': 56.325674057006836, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [167, 152, 134],\n",
       "         [164, 148, 133],\n",
       "         [163, 147, 132]],\n",
       " \n",
       "        [[179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [165, 150, 132],\n",
       "         [163, 147, 132],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        [[179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [161, 146, 128],\n",
       "         [161, 145, 130],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126,  97,  86],\n",
       "         [126,  97,  86],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[125,  96,  85],\n",
       "         [125,  96,  85],\n",
       "         [124,  95,  84],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[125,  96,  85],\n",
       "         [125,  96,  85],\n",
       "         [124,  95,  84],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0061264038085938, 'inference': 28.771162033081055, 'postprocess': 15.623092651367188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [156, 141, 123],\n",
       "         [156, 140, 125],\n",
       "         [156, 140, 125]],\n",
       " \n",
       "        [[179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [154, 139, 121],\n",
       "         [154, 138, 123],\n",
       "         [156, 140, 125]],\n",
       " \n",
       "        [[179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [153, 139, 124],\n",
       "         [153, 139, 124],\n",
       "         [153, 139, 124]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [128,  99,  88],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [128,  99,  88],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [128,  99,  88],\n",
       "         [125,  96,  85],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.0017623901367188, 'inference': 56.079864501953125, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [160, 143, 130],\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        [[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [160, 143, 130],\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        [[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [160, 143, 130],\n",
       "         [162, 147, 134],\n",
       "         [165, 150, 137]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 102,  89],\n",
       "         [129, 101,  88],\n",
       "         [128, 100,  87],\n",
       "         ...,\n",
       "         [122,  97,  88],\n",
       "         [122,  97,  88],\n",
       "         [122,  97,  88]],\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [129, 101,  88],\n",
       "         [126,  98,  85],\n",
       "         ...,\n",
       "         [124,  99,  90],\n",
       "         [122,  97,  88],\n",
       "         [122,  97,  88]],\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [129, 101,  88],\n",
       "         [126,  98,  85],\n",
       "         ...,\n",
       "         [124,  99,  90],\n",
       "         [124,  99,  90],\n",
       "         [122,  97,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.008749008178711, 'inference': 50.273895263671875, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [160, 145, 132],\n",
       "         [161, 146, 133],\n",
       "         [163, 148, 135]],\n",
       " \n",
       "        [[182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [166, 151, 138],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139]],\n",
       " \n",
       "        [[182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [168, 153, 140],\n",
       "         [173, 159, 144],\n",
       "         [169, 155, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [127, 100,  89],\n",
       "         [126,  99,  88],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         [124,  97,  86],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         [124,  97,  86],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.001596450805664, 'inference': 45.68076133728027, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [161, 146, 133],\n",
       "         [162, 147, 134],\n",
       "         [162, 147, 134]],\n",
       " \n",
       "        [[182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138]],\n",
       " \n",
       "        [[182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [169, 155, 140],\n",
       "         [168, 154, 139],\n",
       "         [167, 153, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [132, 104,  91],\n",
       "         [132, 104,  91],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [131, 103,  90],\n",
       "         [130, 102,  89],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[130, 102,  89],\n",
       "         [130, 102,  89],\n",
       "         [130, 102,  89],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [124,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.0096302032470703, 'inference': 40.89832305908203, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [163, 148, 135],\n",
       "         [163, 148, 135],\n",
       "         [163, 148, 135]],\n",
       " \n",
       "        [[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [167, 152, 139]],\n",
       " \n",
       "        [[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [168, 154, 139],\n",
       "         [167, 153, 138],\n",
       "         [167, 153, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.013683319091797, 'inference': 52.09946632385254, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         [179, 163, 148],\n",
       "         ...,\n",
       "         [162, 147, 134],\n",
       "         [160, 145, 132],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        [[182, 166, 151],\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         ...,\n",
       "         [166, 151, 138],\n",
       "         [163, 148, 135],\n",
       "         [162, 147, 134]],\n",
       " \n",
       "        [[182, 166, 151],\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         ...,\n",
       "         [167, 153, 138],\n",
       "         [166, 152, 137],\n",
       "         [165, 151, 136]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86]],\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [121,  94,  83],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.002239227294922, 'inference': 107.26261138916016, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         [179, 163, 148],\n",
       "         ...,\n",
       "         [160, 145, 132],\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        [[181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         [179, 163, 148],\n",
       "         ...,\n",
       "         [161, 146, 133],\n",
       "         [159, 144, 131],\n",
       "         [159, 144, 131]],\n",
       " \n",
       "        [[181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         ...,\n",
       "         [162, 147, 134],\n",
       "         [161, 146, 133],\n",
       "         [161, 146, 133]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [122,  95,  84],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [122,  95,  84],\n",
       "         [121,  94,  83],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [122,  95,  84],\n",
       "         [121,  94,  83],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 16.450881958007812, 'inference': 97.70417213439941, 'postprocess': 15.651941299438477},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[181, 164, 151],\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149],\n",
       "         ...,\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        [[181, 164, 151],\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149],\n",
       "         ...,\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        [[181, 164, 151],\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149],\n",
       "         ...,\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130],\n",
       "         [158, 143, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 48.686981201171875, 'postprocess': 14.43934440612793},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 163, 148],\n",
       "         [179, 163, 148],\n",
       "         [181, 163, 148],\n",
       "         ...,\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        [[179, 163, 148],\n",
       "         [179, 163, 148],\n",
       "         [181, 163, 148],\n",
       "         ...,\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        [[179, 163, 148],\n",
       "         [179, 163, 148],\n",
       "         [181, 163, 148],\n",
       "         ...,\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131],\n",
       "         [161, 145, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [124,  96,  88],\n",
       "         ...,\n",
       "         [122,  98,  86],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [124,  96,  88],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [124,  96,  88],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.99945068359375, 'inference': 49.221038818359375, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 161, 146],\n",
       "         [178, 162, 147],\n",
       "         [181, 163, 148],\n",
       "         ...,\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        [[177, 161, 146],\n",
       "         [179, 163, 148],\n",
       "         [181, 163, 148],\n",
       "         ...,\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        [[178, 162, 147],\n",
       "         [179, 163, 148],\n",
       "         [181, 163, 148],\n",
       "         ...,\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131],\n",
       "         [162, 146, 131]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 102,  94],\n",
       "         [126,  98,  90],\n",
       "         [124,  96,  88],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[131, 103,  95],\n",
       "         [127,  99,  91],\n",
       "         [123,  95,  87],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [124,  96,  88],\n",
       "         [126,  98,  90],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84],\n",
       "         [119,  95,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 42.22464561462402, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 167, 152],\n",
       "         [183, 167, 152],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [165, 149, 134],\n",
       "         [165, 149, 134],\n",
       "         [165, 149, 134]],\n",
       " \n",
       "        [[184, 168, 153],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         ...,\n",
       "         [165, 149, 134],\n",
       "         [165, 149, 134],\n",
       "         [165, 149, 134]],\n",
       " \n",
       "        [[183, 167, 152],\n",
       "         [182, 166, 151],\n",
       "         [181, 165, 150],\n",
       "         ...,\n",
       "         [164, 148, 133],\n",
       "         [164, 148, 133],\n",
       "         [164, 148, 133]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126,  98,  90],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82]],\n",
       " \n",
       "        [[126,  98,  90],\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [126,  98,  90],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.5068778991699219, 'inference': 44.66962814331055, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[186, 168, 153],\n",
       "         [186, 168, 153],\n",
       "         [186, 168, 153],\n",
       "         ...,\n",
       "         [179, 163, 148],\n",
       "         [179, 163, 148],\n",
       "         [179, 163, 148]],\n",
       " \n",
       "        [[184, 166, 151],\n",
       "         [184, 166, 151],\n",
       "         [183, 165, 150],\n",
       "         ...,\n",
       "         [179, 163, 148],\n",
       "         [179, 163, 148],\n",
       "         [181, 165, 150]],\n",
       " \n",
       "        [[184, 167, 149],\n",
       "         [184, 167, 149],\n",
       "         [184, 167, 149],\n",
       "         ...,\n",
       "         [178, 162, 147],\n",
       "         [179, 163, 148],\n",
       "         [181, 165, 150]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 100,  92],\n",
       "         [127,  99,  91],\n",
       "         [129, 101,  93],\n",
       "         ...,\n",
       "         [116,  96,  86],\n",
       "         [116,  96,  86],\n",
       "         [116,  96,  86]],\n",
       " \n",
       "        [[130, 102,  94],\n",
       "         [127,  99,  91],\n",
       "         [128, 100,  92],\n",
       "         ...,\n",
       "         [116,  96,  86],\n",
       "         [116,  96,  86],\n",
       "         [116,  96,  86]],\n",
       " \n",
       "        [[128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [116,  96,  86],\n",
       "         [116,  96,  86],\n",
       "         [116,  96,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.001119613647461, 'inference': 65.33384323120117, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 159, 141],\n",
       "         [173, 160, 142],\n",
       "         [175, 162, 144],\n",
       "         ...,\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151]],\n",
       " \n",
       "        [[174, 161, 143],\n",
       "         [174, 161, 143],\n",
       "         [177, 164, 146],\n",
       "         ...,\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150]],\n",
       " \n",
       "        [[176, 163, 145],\n",
       "         [176, 163, 145],\n",
       "         [179, 166, 148],\n",
       "         ...,\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150],\n",
       "         [181, 165, 150]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [133, 103,  95],\n",
       "         [131, 101,  93],\n",
       "         ...,\n",
       "         [115,  95,  87],\n",
       "         [115,  95,  87],\n",
       "         [115,  95,  87]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [133, 103,  95],\n",
       "         [131, 101,  93],\n",
       "         ...,\n",
       "         [116,  96,  88],\n",
       "         [116,  96,  88],\n",
       "         [116,  96,  88]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [133, 103,  95],\n",
       "         [131, 101,  93],\n",
       "         ...,\n",
       "         [116,  96,  88],\n",
       "         [116,  96,  88],\n",
       "         [116,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0211467742919922, 'inference': 29.981136322021484, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 157, 139],\n",
       "         [174, 161, 143],\n",
       "         [179, 166, 148],\n",
       "         ...,\n",
       "         [183, 167, 152],\n",
       "         [183, 167, 152],\n",
       "         [183, 167, 152]],\n",
       " \n",
       "        [[172, 159, 141],\n",
       "         [173, 160, 142],\n",
       "         [177, 164, 146],\n",
       "         ...,\n",
       "         [183, 167, 152],\n",
       "         [183, 167, 152],\n",
       "         [183, 167, 152]],\n",
       " \n",
       "        [[172, 159, 141],\n",
       "         [174, 161, 143],\n",
       "         [177, 164, 146],\n",
       "         ...,\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [135, 106,  95],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [115,  95,  87],\n",
       "         [115,  95,  87],\n",
       "         [115,  95,  87]],\n",
       " \n",
       "        [[132, 102,  94],\n",
       "         [133, 103,  95],\n",
       "         [131, 101,  93],\n",
       "         ...,\n",
       "         [115,  95,  87],\n",
       "         [115,  95,  87],\n",
       "         [115,  95,  87]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [133, 103,  95],\n",
       "         [131, 101,  93],\n",
       "         ...,\n",
       "         [116,  96,  88],\n",
       "         [116,  96,  88],\n",
       "         [116,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 74.21731948852539, 'postprocess': 15.605926513671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 159, 144],\n",
       "         [175, 159, 144],\n",
       "         [175, 159, 144],\n",
       "         ...,\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [175, 159, 144],\n",
       "         [177, 161, 146],\n",
       "         ...,\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [176, 160, 145],\n",
       "         [177, 161, 146],\n",
       "         ...,\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [135, 106,  95],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0013580322265625, 'inference': 56.330204010009766, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 159, 144],\n",
       "         [173, 159, 144],\n",
       "         [173, 159, 144],\n",
       "         ...,\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[173, 159, 144],\n",
       "         [173, 159, 144],\n",
       "         [174, 160, 145],\n",
       "         ...,\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[172, 158, 143],\n",
       "         [173, 159, 144],\n",
       "         [175, 161, 146],\n",
       "         ...,\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [131, 104,  93],\n",
       "         [134, 107,  96],\n",
       "         ...,\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82],\n",
       "         [116,  94,  82]],\n",
       " \n",
       "        [[130, 102,  94],\n",
       "         [131, 103,  95],\n",
       "         [131, 103,  95],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82]],\n",
       " \n",
       "        [[130, 102,  94],\n",
       "         [131, 103,  95],\n",
       "         [130, 102,  94],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.71661376953125, 'inference': 60.36257743835449, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 159, 144],\n",
       "         [175, 159, 144],\n",
       "         [175, 159, 144],\n",
       "         ...,\n",
       "         [183, 167, 152],\n",
       "         [183, 167, 152],\n",
       "         [183, 167, 152]],\n",
       " \n",
       "        [[175, 159, 144],\n",
       "         [175, 159, 144],\n",
       "         [176, 160, 145],\n",
       "         ...,\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151]],\n",
       " \n",
       "        [[174, 158, 143],\n",
       "         [175, 159, 144],\n",
       "         [177, 161, 146],\n",
       "         ...,\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151],\n",
       "         [182, 166, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  97,  83],\n",
       "         [119,  96,  82],\n",
       "         [119,  96,  82]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  97,  83],\n",
       "         [119,  96,  82],\n",
       "         [119,  96,  82]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [120,  97,  83],\n",
       "         [119,  96,  82],\n",
       "         [119,  96,  82]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.002716064453125, 'inference': 64.15390968322754, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 158, 143],\n",
       "         [176, 162, 147],\n",
       "         [180, 166, 151],\n",
       "         ...,\n",
       "         [181, 164, 151],\n",
       "         [181, 164, 151],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[172, 158, 143],\n",
       "         [175, 161, 146],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [181, 164, 151],\n",
       "         [181, 164, 151],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[173, 159, 144],\n",
       "         [176, 162, 147],\n",
       "         [179, 165, 150],\n",
       "         ...,\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0008811950683594, 'inference': 65.63496589660645, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 161, 145],\n",
       "         [174, 163, 147],\n",
       "         [178, 167, 151],\n",
       "         ...,\n",
       "         [182, 165, 152],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[172, 161, 145],\n",
       "         [177, 166, 150],\n",
       "         [178, 167, 151],\n",
       "         ...,\n",
       "         [182, 165, 152],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[174, 163, 147],\n",
       "         [177, 166, 150],\n",
       "         [180, 169, 153],\n",
       "         ...,\n",
       "         [181, 164, 151],\n",
       "         [182, 165, 152],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 98.82211685180664, 'postprocess': 0.99945068359375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 161, 146],\n",
       "         [179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         ...,\n",
       "         [179, 162, 149],\n",
       "         [182, 165, 152],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        [[179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         [182, 168, 153],\n",
       "         ...,\n",
       "         [178, 161, 148],\n",
       "         [181, 164, 151],\n",
       "         [182, 165, 152]],\n",
       " \n",
       "        [[181, 167, 152],\n",
       "         [183, 169, 154],\n",
       "         [184, 170, 155],\n",
       "         ...,\n",
       "         [176, 159, 146],\n",
       "         [179, 162, 149],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0085105895996094, 'inference': 44.811248779296875, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [164, 147, 134],\n",
       "         [169, 152, 139],\n",
       "         [171, 154, 141]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [164, 147, 134],\n",
       "         [169, 152, 139],\n",
       "         [170, 153, 140]],\n",
       " \n",
       "        [[186, 167, 154],\n",
       "         [186, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [167, 150, 137],\n",
       "         [168, 151, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85],\n",
       "         [121,  97,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 54.43572998046875, 'postprocess': 2.001047134399414},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [163, 146, 133],\n",
       "         [165, 148, 135],\n",
       "         [168, 151, 138]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [163, 146, 133],\n",
       "         [165, 148, 135]],\n",
       " \n",
       "        [[187, 164, 155],\n",
       "         [187, 164, 155],\n",
       "         [187, 164, 155],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [163, 146, 133],\n",
       "         [164, 147, 134]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  89],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  89],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  89],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.000093460083008, 'inference': 38.861989974975586, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [162, 145, 132],\n",
       "         [164, 147, 134]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [162, 145, 132],\n",
       "         [164, 147, 134]],\n",
       " \n",
       "        [[188, 165, 156],\n",
       "         [187, 164, 155],\n",
       "         [187, 164, 155],\n",
       "         ...,\n",
       "         [163, 144, 131],\n",
       "         [163, 144, 131],\n",
       "         [164, 145, 132]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  89],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  89],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  96,  89],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0013580322265625, 'inference': 38.0406379699707, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [162, 145, 132],\n",
       "         [163, 146, 133]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [160, 143, 130],\n",
       "         [160, 143, 130],\n",
       "         [161, 144, 131]],\n",
       " \n",
       "        [[188, 165, 156],\n",
       "         [187, 164, 155],\n",
       "         [187, 164, 155],\n",
       "         ...,\n",
       "         [159, 140, 127],\n",
       "         [160, 141, 128],\n",
       "         [162, 143, 130]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [124,  96,  90],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [126,  98,  92],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [124,  96,  90],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 49.24607276916504, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [164, 147, 134],\n",
       "         [164, 147, 134]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [162, 145, 132],\n",
       "         [163, 146, 133],\n",
       "         [164, 147, 134]],\n",
       " \n",
       "        [[187, 164, 155],\n",
       "         [187, 164, 155],\n",
       "         [188, 165, 156],\n",
       "         ...,\n",
       "         [162, 143, 130],\n",
       "         [163, 144, 131],\n",
       "         [164, 145, 132]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [122,  97,  88],\n",
       "         [119,  97,  85],\n",
       "         [119,  97,  85]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [122,  97,  88],\n",
       "         [120,  98,  86],\n",
       "         [119,  97,  85]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [122,  97,  88],\n",
       "         [120,  98,  86],\n",
       "         [120,  98,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.2218952178955078, 'inference': 49.99518394470215, 'postprocess': 1.9071102142333984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [164, 147, 134],\n",
       "         [168, 151, 138],\n",
       "         [170, 153, 140]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [164, 147, 134],\n",
       "         [169, 152, 139],\n",
       "         [170, 153, 140]],\n",
       " \n",
       "        [[185, 165, 155],\n",
       "         [185, 165, 155],\n",
       "         [184, 164, 154],\n",
       "         ...,\n",
       "         [165, 146, 133],\n",
       "         [169, 150, 137],\n",
       "         [171, 152, 139]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [121,  98,  84],\n",
       "         [121,  98,  84]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [122,  99,  85],\n",
       "         [121,  98,  84]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [122,  99,  85],\n",
       "         [122,  99,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 115.90933799743652, 'postprocess': 2.0508766174316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [185, 168, 155],\n",
       "         [186, 169, 156],\n",
       "         ...,\n",
       "         [171, 152, 139],\n",
       "         [176, 157, 144],\n",
       "         [176, 157, 144]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         ...,\n",
       "         [170, 151, 138],\n",
       "         [174, 155, 142],\n",
       "         [174, 155, 142]],\n",
       " \n",
       "        [[184, 164, 154],\n",
       "         [183, 163, 153],\n",
       "         [184, 164, 154],\n",
       "         ...,\n",
       "         [165, 150, 137],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.9969215393066406, 'inference': 97.11527824401855, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[185, 168, 155],\n",
       "         [186, 169, 156],\n",
       "         [185, 168, 155],\n",
       "         ...,\n",
       "         [176, 157, 144],\n",
       "         [176, 157, 144],\n",
       "         [176, 157, 144]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         [184, 167, 154],\n",
       "         ...,\n",
       "         [174, 155, 142],\n",
       "         [174, 155, 142],\n",
       "         [174, 155, 142]],\n",
       " \n",
       "        [[183, 163, 153],\n",
       "         [184, 164, 154],\n",
       "         [185, 165, 155],\n",
       "         ...,\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.0051002502441406, 'inference': 90.66438674926758, 'postprocess': 9.013652801513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[184, 167, 154],\n",
       "         [183, 166, 153],\n",
       "         [183, 166, 153],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [179, 164, 151],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[183, 166, 153],\n",
       "         [182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [179, 164, 151],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[185, 165, 155],\n",
       "         [184, 164, 154],\n",
       "         [181, 163, 153],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [175, 163, 149],\n",
       "         [177, 165, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0046958923339844, 'inference': 60.339927673339844, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[183, 166, 153],\n",
       "         [182, 165, 152],\n",
       "         [182, 164, 154],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[182, 165, 152],\n",
       "         [182, 165, 152],\n",
       "         [182, 164, 154],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[183, 163, 153],\n",
       "         [183, 163, 153],\n",
       "         [183, 165, 155],\n",
       "         ...,\n",
       "         [178, 166, 152],\n",
       "         [178, 166, 152],\n",
       "         [177, 165, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [131, 103,  90],\n",
       "         [131, 103,  90],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [129, 101,  88],\n",
       "         [129, 101,  88],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [129, 101,  88],\n",
       "         [130, 102,  89],\n",
       "         ...,\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.810955047607422, 'inference': 49.12543296813965, 'postprocess': 1.0118484497070312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[181, 164, 151],\n",
       "         [182, 165, 152],\n",
       "         [182, 164, 154],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[181, 164, 151],\n",
       "         [181, 164, 151],\n",
       "         [179, 161, 151],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [177, 162, 149],\n",
       "         [176, 161, 148]],\n",
       " \n",
       "        [[178, 160, 150],\n",
       "         [179, 161, 151],\n",
       "         [178, 160, 150],\n",
       "         ...,\n",
       "         [177, 165, 151],\n",
       "         [175, 163, 149],\n",
       "         [174, 162, 148]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [130, 102,  89],\n",
       "         [128, 100,  87],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [129, 101,  88],\n",
       "         [130, 102,  89],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [130, 102,  89],\n",
       "         [131, 103,  90],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.9999275207519531, 'inference': 46.69785499572754, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[182, 164, 154],\n",
       "         [178, 160, 150],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[179, 161, 151],\n",
       "         [177, 159, 149],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148]],\n",
       " \n",
       "        [[178, 160, 150],\n",
       "         [176, 158, 148],\n",
       "         [175, 157, 147],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [174, 162, 148],\n",
       "         [174, 162, 148]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128,  99,  88],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [133, 104,  93],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.332925796508789, 'inference': 127.99453735351562, 'postprocess': 3.014087677001953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148]],\n",
       " \n",
       "        [[175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         ...,\n",
       "         [171, 162, 146],\n",
       "         [171, 162, 146],\n",
       "         [171, 162, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.2323856353759766, 'inference': 89.00570869445801, 'postprocess': 70.1131820678711},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148]],\n",
       " \n",
       "        [[175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148],\n",
       "         [175, 164, 148]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [174, 157, 144],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [171, 162, 146],\n",
       "         [171, 162, 146],\n",
       "         [171, 162, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.005411148071289, 'inference': 47.37353324890137, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 159, 146],\n",
       "         [175, 158, 145],\n",
       "         [177, 160, 147],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[175, 158, 145],\n",
       "         [176, 159, 146],\n",
       "         [178, 161, 148],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[174, 157, 144],\n",
       "         [176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         ...,\n",
       "         [171, 161, 147],\n",
       "         [171, 161, 147],\n",
       "         [171, 161, 147]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [131, 104,  93],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         [131, 104,  93],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.008676528930664, 'inference': 50.75407028198242, 'postprocess': 0.9980201721191406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [177, 160, 147],\n",
       "         [174, 157, 144],\n",
       "         [171, 154, 141]],\n",
       " \n",
       "        [[176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [177, 160, 147],\n",
       "         [174, 157, 144],\n",
       "         [172, 155, 142]],\n",
       " \n",
       "        [[176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [177, 160, 147],\n",
       "         [174, 157, 144],\n",
       "         [172, 155, 142]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 101,  93],\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [127, 100,  89],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [127, 100,  89],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.973867416381836, 'inference': 55.04345893859863, 'postprocess': 1.9996166229248047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         [176, 159, 146],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[127,  99,  93],\n",
       "         [128, 100,  94],\n",
       "         [128, 100,  94],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.9973049163818359, 'inference': 59.35478210449219, 'postprocess': 0.9992122650146484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [177, 160, 147],\n",
       "         [176, 159, 146],\n",
       "         [175, 158, 145]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [178, 161, 148],\n",
       "         [177, 160, 147],\n",
       "         [176, 159, 146]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [179, 162, 149],\n",
       "         [178, 161, 148],\n",
       "         [177, 160, 147]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [124,  96,  90],\n",
       "         [124,  96,  90],\n",
       "         [124,  96,  90]],\n",
       " \n",
       "        [[128, 100,  94],\n",
       "         [127,  99,  93],\n",
       "         [126,  98,  92],\n",
       "         ...,\n",
       "         [123,  95,  89],\n",
       "         [123,  95,  89],\n",
       "         [123,  95,  89]],\n",
       " \n",
       "        [[128, 100,  94],\n",
       "         [127,  99,  93],\n",
       "         [127,  99,  93],\n",
       "         ...,\n",
       "         [123,  95,  89],\n",
       "         [123,  95,  89],\n",
       "         [123,  95,  89]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.0018348693847656, 'inference': 62.218666076660156, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 158, 145],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         [168, 153, 140]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         ...,\n",
       "         [123,  95,  89],\n",
       "         [122,  94,  88],\n",
       "         [122,  94,  88]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [124,  96,  90],\n",
       "         [124,  96,  90],\n",
       "         [124,  96,  90]],\n",
       " \n",
       "        [[126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         [126,  98,  90],\n",
       "         ...,\n",
       "         [123,  95,  89],\n",
       "         [123,  95,  89],\n",
       "         [123,  95,  89]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.51192092895508, 'postprocess': 15.62643051147461},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 163, 149],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 163, 149],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 163, 149],\n",
       "         ...,\n",
       "         [174, 159, 146],\n",
       "         [179, 164, 151],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]],\n",
       " \n",
       "        [[129, 101,  93],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]],\n",
       " \n",
       "        [[127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 42.33884811401367, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[179, 164, 151],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [180, 165, 152],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [180, 165, 152],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[179, 164, 151],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [120,  96,  84],\n",
       "         [119,  95,  83],\n",
       "         [118,  94,  82]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 71.27737998962402, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[169, 153, 143],\n",
       "         [169, 153, 143],\n",
       "         [172, 156, 146],\n",
       "         ...,\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[169, 153, 143],\n",
       "         [169, 153, 143],\n",
       "         [172, 156, 146],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[170, 154, 144],\n",
       "         [170, 154, 144],\n",
       "         [172, 156, 146],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [131, 103,  90],\n",
       "         [132, 104,  91],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [119,  95,  83],\n",
       "         [119,  95,  83]],\n",
       " \n",
       "        [[128, 100,  87],\n",
       "         [128, 100,  87],\n",
       "         [131, 103,  90],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82]],\n",
       " \n",
       "        [[128, 100,  87],\n",
       "         [128, 100,  87],\n",
       "         [130, 102,  89],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82],\n",
       "         [117,  93,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 53.9393424987793, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [182, 167, 154],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [177, 162, 149],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 101,  88],\n",
       "         [132, 104,  91],\n",
       "         [133, 105,  92],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82],\n",
       "         [118,  94,  82]],\n",
       " \n",
       "        [[128, 100,  87],\n",
       "         [131, 103,  90],\n",
       "         [133, 105,  92],\n",
       "         ...,\n",
       "         [117,  93,  81],\n",
       "         [117,  93,  81],\n",
       "         [117,  93,  81]],\n",
       " \n",
       "        [[128, 100,  87],\n",
       "         [129, 101,  88],\n",
       "         [133, 105,  92],\n",
       "         ...,\n",
       "         [118,  94,  82],\n",
       "         [117,  93,  81],\n",
       "         [117,  93,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 40.15493392944336, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 157, 147],\n",
       "         [173, 157, 147],\n",
       "         [173, 157, 147],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        [[175, 159, 149],\n",
       "         [175, 159, 149],\n",
       "         [174, 158, 148],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        [[177, 161, 151],\n",
       "         [176, 160, 150],\n",
       "         [175, 159, 149],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 100,  87],\n",
       "         [130, 102,  89],\n",
       "         [135, 107,  94],\n",
       "         ...,\n",
       "         [118,  93,  84],\n",
       "         [117,  92,  83],\n",
       "         [117,  92,  83]],\n",
       " \n",
       "        [[126,  98,  85],\n",
       "         [129, 101,  88],\n",
       "         [133, 105,  92],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[126,  98,  85],\n",
       "         [129, 101,  88],\n",
       "         [133, 105,  92],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 81.59875869750977, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151],\n",
       "         [179, 164, 151]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128,  99,  88],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 15.632867813110352, 'inference': 63.77553939819336, 'postprocess': 6.380796432495117},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[176, 159, 146],\n",
       "         [177, 160, 147],\n",
       "         [175, 158, 145],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 56.29110336303711, 'postprocess': 1.3461112976074219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [172, 162, 148],\n",
       "         [169, 159, 145],\n",
       "         [168, 158, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 76.0345458984375, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [172, 160, 146],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [172, 160, 146],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [173, 163, 149],\n",
       "         [170, 159, 148],\n",
       "         [168, 157, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 47.399044036865234, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [177, 165, 151],\n",
       "         [175, 163, 149],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 163, 149],\n",
       "         [174, 162, 148],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [173, 163, 149],\n",
       "         [172, 162, 148],\n",
       "         [169, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 67.09456443786621, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [179, 165, 150],\n",
       "         [179, 165, 150]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.9483566284179688, 'inference': 45.73845863342285, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [184, 170, 155],\n",
       "         [184, 170, 155],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [119,  95,  83],\n",
       "         [120,  96,  84],\n",
       "         [120,  96,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.89505958557129, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154],\n",
       "         [184, 170, 155]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154],\n",
       "         [184, 170, 155]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 90.30961990356445, 'postprocess': 15.622854232788086},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [182, 168, 153],\n",
       "         [186, 172, 157]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [183, 169, 154],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [129, 100,  89],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [130, 101,  90],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 70.85561752319336, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [183, 169, 154],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [129, 100,  89],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [129, 100,  89],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129, 100,  89],\n",
       "         [130, 101,  90],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 14.5111083984375, 'inference': 94.34914588928223, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 125.28777122497559, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152]],\n",
       " \n",
       "        [[177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [182, 168, 153],\n",
       "         [182, 168, 153]],\n",
       " \n",
       "        [[176, 162, 147],\n",
       "         [176, 162, 147],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 5.42140007019043, 'inference': 183.5012435913086, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152]],\n",
       " \n",
       "        [[177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [179, 165, 150],\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 114.21656608581543, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152]],\n",
       " \n",
       "        [[177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152],\n",
       "         [181, 167, 152]],\n",
       " \n",
       "        [[177, 163, 148],\n",
       "         [177, 163, 148],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [129,  99,  91],\n",
       "         [128,  98,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [129,  99,  91],\n",
       "         [128,  98,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [130, 100,  92],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.94393539428711, 'postprocess': 2.178192138671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        [[177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        [[177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [182, 168, 153],\n",
       "         [183, 169, 154],\n",
       "         [183, 169, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 101,  93],\n",
       "         [130, 100,  92],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [129,  99,  91],\n",
       "         [128,  98,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 63.863277435302734, 'postprocess': 1.9707679748535156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[139, 111,  98],\n",
       "         [135, 107,  94],\n",
       "         [129, 101,  88],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[131, 101,  93],\n",
       "         [130, 100,  92],\n",
       "         [128,  98,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 100,  92],\n",
       "         [128,  98,  90],\n",
       "         [129,  99,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 78.35626602172852, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 108,  95],\n",
       "         [132, 104,  91],\n",
       "         [131, 103,  90],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [129, 100,  89],\n",
       "         [128,  99,  88],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [128,  99,  88],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.1687278747558594, 'inference': 81.94708824157715, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 57.29031562805176, 'postprocess': 1.506805419921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [119,  91,  83],\n",
       "         [117,  89,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 2.171039581298828, 'inference': 55.81974983215332, 'postprocess': 1.3124942779541016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [117,  89,  81],\n",
       "         [117,  89,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 74.21040534973145, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 157, 144],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152],\n",
       "         [180, 165, 152]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [133, 104,  93],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84],\n",
       "         [119,  91,  83]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [133, 104,  93],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [119,  91,  83],\n",
       "         [117,  89,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 47.26147651672363, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [173, 161, 147],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [173, 161, 147],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[169, 154, 141],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [173, 161, 147],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [119,  92,  81],\n",
       "         [117,  90,  79],\n",
       "         [119,  92,  81]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [117,  90,  79],\n",
       "         [117,  90,  79],\n",
       "         [122,  95,  84]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [117,  90,  79],\n",
       "         [120,  93,  82],\n",
       "         [123,  96,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 42.06442832946777, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [170, 158, 144],\n",
       "         [168, 156, 142]],\n",
       " \n",
       "        [[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [170, 158, 144],\n",
       "         [168, 156, 142]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144],\n",
       "         [168, 156, 142]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [123,  95,  87],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [121,  93,  85],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [120,  92,  84],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 44.51274871826172, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 150, 140],\n",
       "         [165, 149, 139],\n",
       "         [162, 146, 136],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [168, 156, 142],\n",
       "         [168, 156, 142]],\n",
       " \n",
       "        [[167, 151, 141],\n",
       "         [166, 150, 140],\n",
       "         [163, 147, 137],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [167, 155, 141],\n",
       "         [167, 155, 141]],\n",
       " \n",
       "        [[167, 151, 141],\n",
       "         [166, 150, 140],\n",
       "         [163, 147, 137],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [166, 154, 140],\n",
       "         [165, 153, 139]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [123,  96,  85],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  94,  83],\n",
       "         [123,  96,  85],\n",
       "         [124,  97,  86]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [130, 101,  90],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  94,  83],\n",
       "         [122,  95,  84],\n",
       "         [123,  96,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 44.722795486450195, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 149, 139],\n",
       "         [162, 146, 136],\n",
       "         [165, 150, 137],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[163, 147, 137],\n",
       "         [162, 146, 136],\n",
       "         [163, 148, 135],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [171, 159, 145],\n",
       "         [172, 160, 146]],\n",
       " \n",
       "        [[163, 147, 137],\n",
       "         [162, 146, 136],\n",
       "         [163, 148, 135],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [122,  95,  84],\n",
       "         [121,  94,  83],\n",
       "         [121,  94,  83]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [119,  91,  83],\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 60.36019325256348, 'postprocess': 4.533052444458008},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [174, 162, 148],\n",
       "         [173, 161, 147]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [173, 161, 147],\n",
       "         [173, 161, 147]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  94,  83],\n",
       "         [121,  94,  83],\n",
       "         [120,  93,  82]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 59.87429618835449, 'postprocess': 5.077838897705078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [174, 159, 146],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [172, 157, 144],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  91,  87],\n",
       "         [120,  91,  87],\n",
       "         [120,  91,  87]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  91,  87],\n",
       "         [120,  91,  87],\n",
       "         [120,  91,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 66.61462783813477, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 53.863525390625, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [168, 156, 142],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86],\n",
       "         [120,  92,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 49.94344711303711, 'postprocess': 1.2645721435546875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [173, 161, 147],\n",
       "         [173, 161, 147]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [173, 161, 147],\n",
       "         [173, 161, 147]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [168, 156, 142],\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 61.89107894897461, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [173, 161, 147],\n",
       "         [173, 161, 147]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [173, 161, 147],\n",
       "         [173, 161, 147]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [124,  95,  84],\n",
       "         [125,  96,  85],\n",
       "         [124,  95,  84]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [124,  94,  86],\n",
       "         [123,  93,  85]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 41.26739501953125, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [163, 148, 135],\n",
       "         [165, 150, 137],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[165, 150, 137],\n",
       "         [165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [174, 162, 148],\n",
       "         [175, 163, 149],\n",
       "         [175, 163, 149]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [172, 160, 146],\n",
       "         [174, 162, 148],\n",
       "         [174, 162, 148]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [124,  95,  84],\n",
       "         [126,  97,  86],\n",
       "         [125,  96,  85]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [122,  93,  82],\n",
       "         [124,  95,  84],\n",
       "         [124,  95,  84]],\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [128, 101,  90],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [122,  93,  82],\n",
       "         [123,  94,  83],\n",
       "         [123,  94,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.881914138793945, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 101,  90],\n",
       "         [127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         ...,\n",
       "         [121,  94,  83],\n",
       "         [123,  96,  85],\n",
       "         [124,  97,  86]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [119,  92,  81],\n",
       "         [121,  94,  83],\n",
       "         [122,  95,  84]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [117,  90,  79],\n",
       "         [120,  93,  82],\n",
       "         [121,  94,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 77.84175872802734, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [124,  94,  86],\n",
       "         [124,  94,  86],\n",
       "         [124,  94,  86]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [122,  92,  84],\n",
       "         [122,  92,  84],\n",
       "         [122,  92,  84]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [121,  91,  83],\n",
       "         [121,  91,  83],\n",
       "         [121,  91,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 31.2502384185791, 'postprocess': 15.625953674316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 104,  93],\n",
       "         [131, 104,  93],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]],\n",
       " \n",
       "        [[131, 104,  93],\n",
       "         [131, 104,  93],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [122,  92,  84],\n",
       "         [121,  91,  83]],\n",
       " \n",
       "        [[131, 104,  93],\n",
       "         [131, 104,  93],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [124,  94,  86],\n",
       "         [122,  92,  84],\n",
       "         [121,  91,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.8754768371582, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [170, 155, 142],\n",
       "         [173, 158, 145],\n",
       "         [174, 159, 146]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [168, 153, 140],\n",
       "         [169, 154, 141],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [122,  92,  84]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [124,  94,  86],\n",
       "         [124,  94,  86],\n",
       "         [122,  92,  84]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [131, 104,  93],\n",
       "         ...,\n",
       "         [124,  94,  86],\n",
       "         [124,  94,  86],\n",
       "         [122,  92,  84]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.87809944152832, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [166, 154, 140],\n",
       "         [166, 154, 140],\n",
       "         [168, 156, 142]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [165, 153, 139],\n",
       "         [165, 153, 139],\n",
       "         [166, 154, 140]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [164, 152, 138],\n",
       "         [163, 151, 137],\n",
       "         [163, 151, 137]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [122,  92,  84],\n",
       "         [124,  94,  86]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [122,  92,  84],\n",
       "         [124,  94,  86]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [122,  92,  84],\n",
       "         [124,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.44993209838867, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [164, 152, 138],\n",
       "         [164, 152, 138],\n",
       "         [163, 151, 137]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [166, 154, 140],\n",
       "         [165, 153, 139],\n",
       "         [163, 151, 137]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [167, 154, 143],\n",
       "         [164, 152, 138],\n",
       "         [164, 152, 138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.50905990600586, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [168, 157, 141],\n",
       "         [166, 155, 139],\n",
       "         [164, 153, 137]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [170, 159, 143],\n",
       "         [167, 156, 140],\n",
       "         [167, 156, 140]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [173, 160, 149],\n",
       "         [172, 159, 148],\n",
       "         [170, 157, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 105,  97],\n",
       "         [133, 105,  97],\n",
       "         [133, 105,  97],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[133, 105,  97],\n",
       "         [133, 105,  97],\n",
       "         [133, 105,  97],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[133, 105,  97],\n",
       "         [133, 105,  97],\n",
       "         [133, 105,  97],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.500953674316406, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[169, 155, 140],\n",
       "         [169, 155, 140],\n",
       "         [169, 155, 140],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[169, 155, 140],\n",
       "         [169, 155, 140],\n",
       "         [169, 155, 140],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         [167, 153, 138],\n",
       "         ...,\n",
       "         [170, 157, 146],\n",
       "         [168, 155, 144],\n",
       "         [168, 155, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.50262260437012, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 157, 141],\n",
       "         [167, 156, 140],\n",
       "         [167, 156, 140],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[168, 157, 141],\n",
       "         [167, 156, 140],\n",
       "         [167, 156, 140],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[166, 155, 139],\n",
       "         [166, 155, 139],\n",
       "         [165, 154, 138],\n",
       "         ...,\n",
       "         [170, 157, 146],\n",
       "         [170, 157, 146],\n",
       "         [168, 155, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84],\n",
       "         [122,  95,  84]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85],\n",
       "         [123,  96,  85]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [124,  97,  86],\n",
       "         [124,  97,  86],\n",
       "         [123,  96,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 47.65129089355469, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 156, 141],\n",
       "         [169, 155, 140],\n",
       "         [169, 155, 140],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144]],\n",
       " \n",
       "        [[169, 155, 140],\n",
       "         [168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         ...,\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145]],\n",
       " \n",
       "        [[169, 155, 140],\n",
       "         [169, 155, 140],\n",
       "         [168, 154, 139],\n",
       "         ...,\n",
       "         [170, 157, 146],\n",
       "         [170, 157, 146],\n",
       "         [168, 155, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [122,  94,  86]],\n",
       " \n",
       "        [[131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [123,  95,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 15.625, 'inference': 73.5630989074707, 'postprocess': 0.5118846893310547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[165, 150, 137],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [172, 159, 148],\n",
       "         [171, 158, 147],\n",
       "         [168, 155, 144]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [173, 160, 149],\n",
       "         [172, 159, 148],\n",
       "         [168, 155, 144]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [171, 158, 149],\n",
       "         [173, 160, 151],\n",
       "         [173, 160, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [122,  94,  86],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [122,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 71.41256332397461, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [168, 156, 142],\n",
       "         [166, 154, 140]],\n",
       " \n",
       "        [[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [171, 159, 145],\n",
       "         [167, 155, 141],\n",
       "         [166, 154, 140]],\n",
       " \n",
       "        [[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [173, 160, 149],\n",
       "         [171, 158, 147],\n",
       "         [170, 157, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [120,  95,  86],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [120,  95,  86],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.87786102294922, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [164, 152, 138],\n",
       "         [160, 148, 134]],\n",
       " \n",
       "        [[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [167, 155, 141],\n",
       "         [164, 152, 138],\n",
       "         [161, 149, 135]],\n",
       " \n",
       "        [[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [167, 154, 143],\n",
       "         [167, 154, 143],\n",
       "         [165, 152, 141]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [120,  92,  84],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 43.92266273498535, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [163, 150, 139],\n",
       "         [163, 150, 139],\n",
       "         [161, 148, 137]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [163, 150, 139],\n",
       "         [161, 148, 137],\n",
       "         [161, 148, 137]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [165, 152, 141],\n",
       "         [165, 152, 141],\n",
       "         [164, 151, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [120,  92,  84],\n",
       "         [120,  92,  84]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [123,  93,  85],\n",
       "         [123,  93,  85],\n",
       "         [122,  92,  84]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         ...,\n",
       "         [124,  94,  86],\n",
       "         [124,  94,  86],\n",
       "         [124,  94,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 9.014368057250977, 'inference': 66.40744209289551, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [164, 151, 140],\n",
       "         [165, 152, 141],\n",
       "         [165, 152, 141]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [165, 152, 141],\n",
       "         [165, 152, 141],\n",
       "         [165, 152, 141]],\n",
       " \n",
       "        [[166, 151, 138],\n",
       "         [166, 151, 138],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [166, 153, 142],\n",
       "         [167, 154, 143],\n",
       "         [167, 154, 143]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85],\n",
       "         [121,  93,  85]],\n",
       " \n",
       "        [[131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88],\n",
       "         [123,  95,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 8.159160614013672, 'inference': 37.95218467712402, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 158, 145],\n",
       "         [174, 159, 146],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [171, 158, 147],\n",
       "         [171, 158, 147],\n",
       "         [172, 159, 148]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [171, 158, 147],\n",
       "         [171, 158, 147],\n",
       "         [171, 158, 147]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [170, 157, 146],\n",
       "         [170, 157, 146],\n",
       "         [170, 157, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [135, 104,  93],\n",
       "         ...,\n",
       "         [120,  95,  86],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [137, 106,  95],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [137, 106,  95],\n",
       "         ...,\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87],\n",
       "         [121,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.502384185791016, 'postprocess': 1.6639232635498047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [166, 153, 142],\n",
       "         [165, 152, 141],\n",
       "         [164, 151, 140]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [166, 153, 142],\n",
       "         [165, 152, 141],\n",
       "         [164, 151, 140]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [167, 154, 143],\n",
       "         [165, 152, 141],\n",
       "         [164, 151, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         [135, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]],\n",
       " \n",
       "        [[136, 107,  96],\n",
       "         [136, 107,  96],\n",
       "         [136, 107,  96],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 61.25140190124512, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [159, 148, 137],\n",
       "         [162, 151, 140],\n",
       "         [162, 151, 140]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [159, 148, 137],\n",
       "         [162, 151, 140],\n",
       "         [162, 151, 140]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [161, 150, 139],\n",
       "         [163, 152, 141],\n",
       "         [163, 152, 141]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 104,  93],\n",
       "         [131, 104,  93],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [131, 104,  93],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [123,  95,  87],\n",
       "         [124,  96,  88]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.884775161743164, 'postprocess': 15.623807907104492},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [174, 159, 146],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [166, 155, 144],\n",
       "         [169, 158, 147],\n",
       "         [170, 159, 148]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [169, 158, 147],\n",
       "         [171, 160, 149],\n",
       "         [171, 160, 149]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [177, 162, 149],\n",
       "         [179, 164, 151],\n",
       "         ...,\n",
       "         [171, 160, 149],\n",
       "         [172, 161, 150],\n",
       "         [173, 162, 151]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [122,  94,  86],\n",
       "         [124,  96,  88],\n",
       "         [126,  98,  90]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [124,  96,  88]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [123,  95,  87],\n",
       "         [124,  96,  88],\n",
       "         [126,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.502145767211914, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 161, 146],\n",
       "         [175, 161, 146],\n",
       "         [175, 161, 146],\n",
       "         ...,\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150]],\n",
       " \n",
       "        [[176, 162, 147],\n",
       "         [176, 162, 147],\n",
       "         [176, 162, 147],\n",
       "         ...,\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150]],\n",
       " \n",
       "        [[175, 161, 146],\n",
       "         [175, 161, 146],\n",
       "         [175, 161, 146],\n",
       "         ...,\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [129,  99,  91],\n",
       "         [130, 100,  92],\n",
       "         [130, 100,  92]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [130, 100,  92],\n",
       "         [131, 101,  93],\n",
       "         [131, 101,  93]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [129,  99,  91],\n",
       "         [129,  99,  91],\n",
       "         [128,  98,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 15.625, 'inference': 47.27816581726074, 'postprocess': 15.626668930053711},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[177, 162, 149],\n",
       "         [177, 162, 149],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150],\n",
       "         [172, 161, 150]],\n",
       " \n",
       "        [[176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [175, 164, 153],\n",
       "         [175, 164, 153],\n",
       "         [175, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [129,  99,  91],\n",
       "         [128,  98,  90],\n",
       "         [128,  98,  90]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  96,  88],\n",
       "         [128,  98,  90],\n",
       "         [128,  98,  90]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  96,  88],\n",
       "         [128,  98,  90],\n",
       "         [129,  99,  91]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.5, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         ...,\n",
       "         [127,  96,  85],\n",
       "         [130,  99,  88],\n",
       "         [130,  99,  88]],\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         ...,\n",
       "         [127,  96,  85],\n",
       "         [130,  99,  88],\n",
       "         [130,  99,  88]],\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         ...,\n",
       "         [130,  99,  88],\n",
       "         [127,  96,  85],\n",
       "         [127,  96,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.499046325683594, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         ...,\n",
       "         [130,  99,  88],\n",
       "         [127,  96,  85],\n",
       "         [126,  95,  84]],\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         ...,\n",
       "         [128,  97,  86],\n",
       "         [128,  97,  86],\n",
       "         [127,  96,  85]],\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         [133, 103,  90],\n",
       "         ...,\n",
       "         [127,  96,  85],\n",
       "         [128,  97,  86],\n",
       "         [127,  96,  85]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.51263618469238, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [173, 158, 145],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [134, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [127,  96,  85],\n",
       "         [127,  96,  85],\n",
       "         [123,  92,  81]],\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [134, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  95,  84],\n",
       "         [124,  93,  82],\n",
       "         [123,  92,  81]],\n",
       " \n",
       "        [[133, 103,  90],\n",
       "         [134, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [126,  95,  84],\n",
       "         [123,  92,  81],\n",
       "         [123,  92,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 47.01685905456543, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         ...,\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [128,  97,  86],\n",
       "         [125,  94,  83],\n",
       "         [125,  94,  83]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [128,  97,  86],\n",
       "         [123,  92,  81],\n",
       "         [123,  92,  81]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [126,  95,  84],\n",
       "         [123,  92,  81],\n",
       "         [123,  92,  81]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.5054473876953125, 'inference': 43.36881637573242, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 167, 153],\n",
       "         [178, 166, 152],\n",
       "         [180, 168, 154]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 167, 153],\n",
       "         [178, 166, 152],\n",
       "         [180, 168, 154]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 167, 153],\n",
       "         [178, 166, 152],\n",
       "         [180, 168, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [133, 104,  93],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [132,  98,  88],\n",
       "         [129,  95,  85],\n",
       "         [130,  96,  86]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [130,  96,  86],\n",
       "         [132,  98,  88],\n",
       "         [132,  98,  88]],\n",
       " \n",
       "        [[132, 103,  92],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [130,  96,  86],\n",
       "         [129,  95,  85],\n",
       "         [130,  96,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 61.39326095581055, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 167, 153],\n",
       "         [180, 168, 154],\n",
       "         [180, 168, 154]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 167, 153],\n",
       "         [180, 168, 154],\n",
       "         [180, 168, 154]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         ...,\n",
       "         [179, 167, 153],\n",
       "         [180, 168, 154],\n",
       "         [180, 168, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[137, 108,  97],\n",
       "         [136, 107,  96],\n",
       "         [133, 104,  93],\n",
       "         ...,\n",
       "         [120,  86,  76],\n",
       "         [118,  84,  74],\n",
       "         [118,  84,  74]],\n",
       " \n",
       "        [[137, 108,  97],\n",
       "         [133, 104,  93],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [121,  87,  77],\n",
       "         [120,  86,  76],\n",
       "         [119,  85,  75]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [131, 102,  91],\n",
       "         [129, 100,  89],\n",
       "         ...,\n",
       "         [128,  94,  84],\n",
       "         [127,  93,  83],\n",
       "         [127,  93,  83]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.5, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [171, 159, 145],\n",
       "         ...,\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158]],\n",
       " \n",
       "        [[172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         ...,\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158]],\n",
       " \n",
       "        [[174, 162, 148],\n",
       "         [173, 161, 147],\n",
       "         [173, 161, 147],\n",
       "         ...,\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  88,  80],\n",
       "         [120,  88,  80],\n",
       "         [120,  88,  80]],\n",
       " \n",
       "        [[130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         [130, 101,  90],\n",
       "         ...,\n",
       "         [120,  86,  76],\n",
       "         [119,  85,  75],\n",
       "         [119,  85,  75]],\n",
       " \n",
       "        [[133, 104,  93],\n",
       "         [132, 103,  92],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [120,  86,  76],\n",
       "         [119,  85,  75],\n",
       "         [119,  85,  75]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.86927795410156, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 156, 142],\n",
       "         [167, 155, 141],\n",
       "         [167, 155, 141],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        [[170, 158, 144],\n",
       "         [168, 156, 142],\n",
       "         [168, 156, 142],\n",
       "         ...,\n",
       "         [179, 166, 155],\n",
       "         [179, 166, 155],\n",
       "         [179, 166, 155]],\n",
       " \n",
       "        [[170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158],\n",
       "         [182, 169, 158]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[132, 104,  91],\n",
       "         [132, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [115,  87,  79],\n",
       "         [114,  86,  78],\n",
       "         [114,  86,  78]],\n",
       " \n",
       "        [[132, 104,  91],\n",
       "         [132, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [115,  87,  79],\n",
       "         [114,  86,  78],\n",
       "         [114,  86,  78]],\n",
       " \n",
       "        [[132, 104,  91],\n",
       "         [132, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [115,  87,  79],\n",
       "         [114,  86,  78],\n",
       "         [114,  86,  78]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.874046325683594, 'postprocess': 15.627861022949219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[171, 159, 145],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [172, 159, 148],\n",
       "         [172, 159, 148],\n",
       "         [172, 159, 148]],\n",
       " \n",
       "        [[171, 159, 145],\n",
       "         [168, 156, 142],\n",
       "         [168, 156, 142],\n",
       "         ...,\n",
       "         [173, 160, 149],\n",
       "         [173, 160, 149],\n",
       "         [173, 160, 149]],\n",
       " \n",
       "        [[168, 156, 142],\n",
       "         [167, 155, 141],\n",
       "         [166, 154, 140],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [132, 104,  91],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [113,  90,  81],\n",
       "         [113,  90,  81],\n",
       "         [113,  90,  81]],\n",
       " \n",
       "        [[132, 104,  91],\n",
       "         [132, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [115,  87,  79],\n",
       "         [115,  87,  79],\n",
       "         [115,  87,  79]],\n",
       " \n",
       "        [[132, 104,  91],\n",
       "         [132, 104,  91],\n",
       "         [132, 103,  92],\n",
       "         ...,\n",
       "         [115,  87,  79],\n",
       "         [115,  87,  79],\n",
       "         [114,  86,  78]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 109.15827751159668, 'postprocess': 1.4374256134033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141]],\n",
       " \n",
       "        [[171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142]],\n",
       " \n",
       "        [[171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 102,  89],\n",
       "         [128, 102,  89],\n",
       "         [128, 101,  90],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [120,  97,  88],\n",
       "         [119,  96,  87]],\n",
       " \n",
       "        [[130, 102,  89],\n",
       "         [131, 103,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [118,  95,  86],\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87]],\n",
       " \n",
       "        [[131, 103,  90],\n",
       "         [131, 103,  90],\n",
       "         [131, 102,  91],\n",
       "         ...,\n",
       "         [117,  94,  85],\n",
       "         [118,  95,  86],\n",
       "         [118,  95,  86]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.5059242248535156, 'inference': 43.27249526977539, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         ...,\n",
       "         [166, 152, 137],\n",
       "         [166, 152, 137],\n",
       "         [166, 152, 137]],\n",
       " \n",
       "        [[172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         [172, 160, 146],\n",
       "         ...,\n",
       "         [167, 153, 138],\n",
       "         [168, 154, 139],\n",
       "         [168, 154, 139]],\n",
       " \n",
       "        [[171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         ...,\n",
       "         [168, 154, 139],\n",
       "         [169, 155, 140],\n",
       "         [169, 155, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87],\n",
       "         [119,  96,  87]],\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [120,  97,  88],\n",
       "         [120,  97,  88]],\n",
       " \n",
       "        [[129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [119,  96,  87],\n",
       "         [120,  97,  88],\n",
       "         [119,  96,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 62.503814697265625, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [168, 154, 139],\n",
       "         [169, 155, 140],\n",
       "         [169, 155, 140]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [167, 153, 138],\n",
       "         [167, 153, 138],\n",
       "         [167, 153, 138]],\n",
       " \n",
       "        [[174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         ...,\n",
       "         [166, 152, 137],\n",
       "         [166, 152, 137],\n",
       "         [166, 152, 137]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [119, 102,  89],\n",
       "         [120, 103,  90],\n",
       "         [121, 104,  91]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [120, 101,  88],\n",
       "         [122, 103,  90],\n",
       "         [122, 103,  90]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [121, 102,  89],\n",
       "         [122, 103,  90],\n",
       "         [122, 103,  90]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 67.53325462341309, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 156, 142],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [174, 160, 145],\n",
       "         [173, 159, 144],\n",
       "         [173, 159, 144]],\n",
       " \n",
       "        [[170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         [170, 158, 144],\n",
       "         ...,\n",
       "         [172, 158, 143],\n",
       "         [172, 158, 143],\n",
       "         [172, 158, 143]],\n",
       " \n",
       "        [[171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         [171, 159, 145],\n",
       "         ...,\n",
       "         [168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         [169, 155, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [121, 102,  89],\n",
       "         [122, 103,  90],\n",
       "         [122, 103,  90]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [118, 101,  88],\n",
       "         [120, 103,  90],\n",
       "         [120, 103,  90]],\n",
       " \n",
       "        [[130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         [130, 103,  92],\n",
       "         ...,\n",
       "         [118, 101,  88],\n",
       "         [120, 103,  90],\n",
       "         [121, 104,  91]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.87047004699707, 'postprocess': 15.627861022949219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [173, 158, 145],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [173, 158, 145],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [123, 100,  91],\n",
       "         [124, 101,  92],\n",
       "         [124, 101,  92]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [120, 100,  90],\n",
       "         [122, 102,  92],\n",
       "         [123, 103,  93]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [130, 104,  91],\n",
       "         ...,\n",
       "         [120, 100,  90],\n",
       "         [122, 102,  92],\n",
       "         [123, 103,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.8754768371582, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146],\n",
       "         [174, 159, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[130, 104,  91],\n",
       "         [130, 104,  91],\n",
       "         [130, 104,  91],\n",
       "         ...,\n",
       "         [123, 100,  91],\n",
       "         [124, 101,  92],\n",
       "         [124, 101,  92]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [122,  99,  90],\n",
       "         [122, 102,  92],\n",
       "         [123, 103,  93]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [130, 104,  91],\n",
       "         ...,\n",
       "         [122,  99,  90],\n",
       "         [122, 102,  92],\n",
       "         [123, 103,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.5511512756347656, 'inference': 62.52622604370117, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [176, 161, 148],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         [173, 158, 145],\n",
       "         ...,\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [124, 101,  92],\n",
       "         [124, 101,  92],\n",
       "         [124, 101,  92]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [123, 100,  91],\n",
       "         [123, 103,  93],\n",
       "         [123, 103,  93]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [130, 104,  91],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [123, 100,  91],\n",
       "         [123, 103,  93],\n",
       "         [123, 103,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 73.60720634460449, 'postprocess': 16.732454299926758},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [124, 101,  92],\n",
       "         [124, 101,  92],\n",
       "         [124, 101,  92]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [122, 102,  92],\n",
       "         [123, 103,  93],\n",
       "         [123, 103,  93]],\n",
       " \n",
       "        [[128, 102,  89],\n",
       "         [128, 102,  89],\n",
       "         [129, 103,  90],\n",
       "         ...,\n",
       "         [122, 102,  92],\n",
       "         [123, 103,  93],\n",
       "         [123, 103,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 5.299806594848633, 'inference': 136.54017448425293, 'postprocess': 1.5244483947753906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[169, 154, 141],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147],\n",
       "         [175, 160, 147]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         ...,\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93]],\n",
       " \n",
       "        [[129, 103,  90],\n",
       "         [129, 103,  90],\n",
       "         [130, 104,  91],\n",
       "         ...,\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 50.180912017822266, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [181, 166, 153],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [179, 164, 151],\n",
       "         [180, 165, 152],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 112,  98],\n",
       "         [135, 112,  98],\n",
       "         [134, 111,  97],\n",
       "         ...,\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92]],\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92]],\n",
       " \n",
       "        [[131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 74.71752166748047, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153],\n",
       "         [181, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [127, 103,  91],\n",
       "         [128, 104,  92],\n",
       "         [128, 104,  92]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [127, 102,  93],\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 73.00519943237305, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155],\n",
       "         [183, 168, 155]],\n",
       " \n",
       "        [[169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [183, 168, 155],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        [[169, 154, 141],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154],\n",
       "         [182, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[137, 111,  98],\n",
       "         [138, 112,  99],\n",
       "         [140, 114, 101],\n",
       "         ...,\n",
       "         [127, 103,  91],\n",
       "         [127, 103,  91],\n",
       "         [127, 103,  91]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93],\n",
       "         [127, 102,  93]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [130, 104,  91],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92],\n",
       "         [126, 101,  92]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.4324188232421875, 'inference': 44.844865798950195, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [181, 166, 153],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [180, 165, 152],\n",
       "         [177, 162, 149],\n",
       "         [177, 162, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[140, 114, 101],\n",
       "         [141, 115, 102],\n",
       "         [142, 116, 103],\n",
       "         ...,\n",
       "         [128,  99,  88],\n",
       "         [128,  99,  88],\n",
       "         [128,  99,  88]],\n",
       " \n",
       "        [[138, 112,  99],\n",
       "         [140, 114, 101],\n",
       "         [140, 114, 101],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 9.007453918457031, 'inference': 55.892229080200195, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[167, 152, 139],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [175, 161, 146],\n",
       "         [174, 160, 145]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [175, 161, 146],\n",
       "         [174, 160, 145]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [166, 151, 138],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [176, 162, 147],\n",
       "         [175, 161, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[138, 112,  99],\n",
       "         [140, 114, 101],\n",
       "         [141, 115, 102],\n",
       "         ...,\n",
       "         [128,  99,  88],\n",
       "         [128,  99,  88],\n",
       "         [128,  99,  88]],\n",
       " \n",
       "        [[138, 112,  99],\n",
       "         [140, 114, 101],\n",
       "         [141, 115, 102],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         ...,\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91],\n",
       "         [129, 102,  91]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 47.26672172546387, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [176, 162, 147],\n",
       "         [174, 160, 145]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [181, 167, 152],\n",
       "         [177, 163, 148],\n",
       "         [175, 161, 146]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [180, 166, 151],\n",
       "         [177, 163, 148],\n",
       "         [175, 161, 146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[138, 113,  97],\n",
       "         [140, 115,  99],\n",
       "         [141, 116, 100],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88],\n",
       "         [126,  99,  88]],\n",
       " \n",
       "        [[137, 112,  96],\n",
       "         [137, 112,  96],\n",
       "         [138, 113,  97],\n",
       "         ...,\n",
       "         [127, 103,  91],\n",
       "         [127, 103,  91],\n",
       "         [127, 103,  91]],\n",
       " \n",
       "        [[136, 111,  95],\n",
       "         [136, 111,  95],\n",
       "         [135, 110,  94],\n",
       "         ...,\n",
       "         [127, 103,  91],\n",
       "         [127, 103,  91],\n",
       "         [127, 103,  91]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 48.399925231933594, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [184, 166, 156],\n",
       "         [181, 163, 153],\n",
       "         [179, 161, 151]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [184, 166, 156],\n",
       "         [181, 163, 153],\n",
       "         [179, 161, 151]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [167, 152, 139],\n",
       "         ...,\n",
       "         [183, 165, 155],\n",
       "         [179, 161, 151],\n",
       "         [178, 160, 150]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [127, 100,  89],\n",
       "         [127, 100,  89],\n",
       "         [127, 100,  89]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [134, 108,  95],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91],\n",
       "         [127,  99,  91]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [131, 105,  92],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.2488365173339844, 'inference': 134.06801223754883, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [181, 164, 151],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [181, 164, 151],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [127,  99,  91],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [135, 109,  96],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [130, 102,  94],\n",
       "         [128, 100,  92],\n",
       "         [129, 101,  93]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 1.1677742004394531, 'inference': 76.34925842285156, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [185, 168, 155],\n",
       "         [184, 167, 154],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [185, 168, 155],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 30.404090881347656, 'postprocess': 15.625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [181, 164, 151],\n",
       "         [178, 161, 148]],\n",
       " \n",
       "        [[168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         [168, 154, 139],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [182, 165, 152],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[170, 156, 141],\n",
       "         [170, 156, 141],\n",
       "         [169, 155, 140],\n",
       "         ...,\n",
       "         [185, 168, 155],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 44.06142234802246, 'postprocess': 12.510061264038086},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [183, 166, 153],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        [[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [183, 166, 153],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        [[172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         [172, 157, 144],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154],\n",
       "         [183, 166, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[134, 111,  97],\n",
       "         [132, 109,  95],\n",
       "         [129, 106,  92],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]],\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [134, 108,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [131, 105,  92],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93],\n",
       "         [129, 101,  93]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.87762260437012, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [183, 166, 153],\n",
       "         [182, 165, 152],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        [[169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [184, 167, 154],\n",
       "         [182, 165, 152],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [185, 168, 155],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [131, 104,  93],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[135, 108,  97],\n",
       "         [134, 107,  96],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[134, 107,  96],\n",
       "         [133, 106,  95],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 14.544010162353516, 'inference': 47.356367111206055, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         [168, 153, 140],\n",
       "         ...,\n",
       "         [182, 165, 152],\n",
       "         [179, 162, 149],\n",
       "         [179, 162, 149]],\n",
       " \n",
       "        [[169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         [169, 154, 141],\n",
       "         ...,\n",
       "         [183, 166, 153],\n",
       "         [181, 164, 151],\n",
       "         [181, 164, 151]],\n",
       " \n",
       "        [[170, 155, 142],\n",
       "         [169, 154, 141],\n",
       "         [170, 155, 142],\n",
       "         ...,\n",
       "         [185, 168, 155],\n",
       "         [184, 167, 154],\n",
       "         [184, 167, 154]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [131, 105,  92],\n",
       "         [131, 104,  93],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[134, 107,  96],\n",
       "         [131, 104,  93],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]],\n",
       " \n",
       "        [[133, 106,  95],\n",
       "         [131, 104,  93],\n",
       "         [133, 106,  95],\n",
       "         ...,\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92],\n",
       "         [128, 100,  92]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 13.523101806640625, 'inference': 97.20706939697266, 'postprocess': 7.365226745605469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 153, 140],\n",
       "         [169, 152, 139],\n",
       "         [169, 152, 139],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [178, 165, 154],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        [[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [178, 165, 154],\n",
       "         [180, 167, 156],\n",
       "         [179, 166, 155]],\n",
       " \n",
       "        [[171, 154, 141],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [183, 167, 157],\n",
       "         [182, 169, 158],\n",
       "         [180, 167, 156]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [127, 100,  89],\n",
       "         [127, 101,  88],\n",
       "         [127, 101,  88]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [127, 100,  89],\n",
       "         [126, 100,  87],\n",
       "         [127, 101,  88]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [127, 100,  89],\n",
       "         [126, 100,  87],\n",
       "         [126, 100,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 47.82247543334961, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [174, 161, 150],\n",
       "         [174, 161, 150],\n",
       "         [173, 160, 149]],\n",
       " \n",
       "        [[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        [[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [181, 165, 155],\n",
       "         [178, 165, 154],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         [136, 110,  97],\n",
       "         ...,\n",
       "         [127, 100,  89],\n",
       "         [127, 101,  88],\n",
       "         [127, 101,  88]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [134, 108,  95],\n",
       "         [134, 108,  95],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [127, 101,  88],\n",
       "         [127, 101,  88]],\n",
       " \n",
       "        [[134, 108,  95],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [126,  99,  88],\n",
       "         [126, 100,  87],\n",
       "         [126, 100,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 49.01838302612305, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [174, 161, 150],\n",
       "         [173, 160, 149],\n",
       "         [173, 160, 149]],\n",
       " \n",
       "        [[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153],\n",
       "         [175, 162, 151]],\n",
       " \n",
       "        [[170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         [170, 153, 140],\n",
       "         ...,\n",
       "         [178, 165, 154],\n",
       "         [177, 164, 153],\n",
       "         [177, 164, 153]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[136, 110,  97],\n",
       "         [137, 111,  98],\n",
       "         [138, 112,  99],\n",
       "         ...,\n",
       "         [127, 101,  88],\n",
       "         [127, 101,  88],\n",
       "         [127, 101,  88]],\n",
       " \n",
       "        [[135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         [135, 109,  96],\n",
       "         ...,\n",
       "         [126, 100,  87],\n",
       "         [127, 101,  88],\n",
       "         [127, 101,  88]],\n",
       " \n",
       "        [[133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         [133, 107,  94],\n",
       "         ...,\n",
       "         [126, 100,  87],\n",
       "         [126, 100,  87],\n",
       "         [126, 100,  87]]], dtype=uint8)\n",
       " orig_shape: (2160, 3840)\n",
       " path: 'C:\\\\Users\\\\BAPS\\\\Documents\\\\Pose_estimation\\\\dance.mp4'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\Users\\\\BAPS\\\\runs\\\\pose\\\\predict2'\n",
       " speed: {'preprocess': 0.0, 'inference': 46.8747615814209, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source='dance.mp4'\n",
    "\n",
    "model.predict(source, save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc5fcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-pose.pt to 'yolov8s-pose.pt'...\n",
      "100%|| 22.4M/22.4M [00:01<00:00, 15.0MB/s]\n",
      "\n",
      "0: 480x640 (no detections), 656.9ms\n",
      "Speed: 14.5ms preprocess, 656.9ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 530.5ms\n",
      "Speed: 4.8ms preprocess, 530.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 446.9ms\n",
      "Speed: 3.0ms preprocess, 446.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 450.1ms\n",
      "Speed: 3.0ms preprocess, 450.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 462.5ms\n",
      "Speed: 4.5ms preprocess, 462.5ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 428.2ms\n",
      "Speed: 3.0ms preprocess, 428.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 448.6ms\n",
      "Speed: 0.0ms preprocess, 448.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 439.4ms\n",
      "Speed: 0.5ms preprocess, 439.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 473.8ms\n",
      "Speed: 3.0ms preprocess, 473.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 435.5ms\n",
      "Speed: 1.0ms preprocess, 435.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 446.5ms\n",
      "Speed: 4.1ms preprocess, 446.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 529.6ms\n",
      "Speed: 3.0ms preprocess, 529.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 554.9ms\n",
      "Speed: 1.0ms preprocess, 554.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 553.5ms\n",
      "Speed: 4.1ms preprocess, 553.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 601.5ms\n",
      "Speed: 0.0ms preprocess, 601.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 516.7ms\n",
      "Speed: 2.5ms preprocess, 516.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 557.6ms\n",
      "Speed: 4.0ms preprocess, 557.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 536.5ms\n",
      "Speed: 7.4ms preprocess, 536.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 548.5ms\n",
      "Speed: 2.4ms preprocess, 548.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 478.4ms\n",
      "Speed: 1.0ms preprocess, 478.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 444.4ms\n",
      "Speed: 4.0ms preprocess, 444.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 442.0ms\n",
      "Speed: 3.2ms preprocess, 442.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 398.9ms\n",
      "Speed: 3.6ms preprocess, 398.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 479.4ms\n",
      "Speed: 0.0ms preprocess, 479.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 493.7ms\n",
      "Speed: 0.0ms preprocess, 493.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 448.9ms\n",
      "Speed: 3.7ms preprocess, 448.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 496.8ms\n",
      "Speed: 0.0ms preprocess, 496.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 496.4ms\n",
      "Speed: 4.0ms preprocess, 496.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 514.1ms\n",
      "Speed: 1.7ms preprocess, 514.1ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 504.2ms\n",
      "Speed: 3.0ms preprocess, 504.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 540.1ms\n",
      "Speed: 1.0ms preprocess, 540.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 485.5ms\n",
      "Speed: 1.4ms preprocess, 485.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 511.0ms\n",
      "Speed: 5.6ms preprocess, 511.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 484.5ms\n",
      "Speed: 4.0ms preprocess, 484.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 459.2ms\n",
      "Speed: 3.1ms preprocess, 459.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 470.8ms\n",
      "Speed: 3.2ms preprocess, 470.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 475.4ms\n",
      "Speed: 0.0ms preprocess, 475.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 495.2ms\n",
      "Speed: 5.1ms preprocess, 495.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 510.0ms\n",
      "Speed: 0.0ms preprocess, 510.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 465.8ms\n",
      "Speed: 0.0ms preprocess, 465.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 510.8ms\n",
      "Speed: 0.0ms preprocess, 510.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 474.1ms\n",
      "Speed: 4.4ms preprocess, 474.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 476.1ms\n",
      "Speed: 5.7ms preprocess, 476.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 463.2ms\n",
      "Speed: 3.1ms preprocess, 463.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 453.9ms\n",
      "Speed: 0.0ms preprocess, 453.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 464.0ms\n",
      "Speed: 2.0ms preprocess, 464.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 452.9ms\n",
      "Speed: 2.2ms preprocess, 452.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 441.5ms\n",
      "Speed: 3.0ms preprocess, 441.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 581.8ms\n",
      "Speed: 1.4ms preprocess, 581.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 586.9ms\n",
      "Speed: 3.0ms preprocess, 586.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 469.0ms\n",
      "Speed: 2.0ms preprocess, 469.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 443.9ms\n",
      "Speed: 0.0ms preprocess, 443.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 489.1ms\n",
      "Speed: 2.5ms preprocess, 489.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 499.8ms\n",
      "Speed: 3.4ms preprocess, 499.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 474.6ms\n",
      "Speed: 0.0ms preprocess, 474.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 565.5ms\n",
      "Speed: 0.0ms preprocess, 565.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 502.0ms\n",
      "Speed: 2.5ms preprocess, 502.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 732.6ms\n",
      "Speed: 0.0ms preprocess, 732.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 948.2ms\n",
      "Speed: 3.1ms preprocess, 948.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 877.3ms\n",
      "Speed: 3.0ms preprocess, 877.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 785.1ms\n",
      "Speed: 9.7ms preprocess, 785.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 551.8ms\n",
      "Speed: 1.3ms preprocess, 551.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 636.3ms\n",
      "Speed: 2.2ms preprocess, 636.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 472.1ms\n",
      "Speed: 0.0ms preprocess, 472.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 443.1ms\n",
      "Speed: 0.0ms preprocess, 443.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 459.5ms\n",
      "Speed: 3.5ms preprocess, 459.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 446.9ms\n",
      "Speed: 0.0ms preprocess, 446.9ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 429.1ms\n",
      "Speed: 0.0ms preprocess, 429.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 472.3ms\n",
      "Speed: 0.0ms preprocess, 472.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 446.7ms\n",
      "Speed: 5.9ms preprocess, 446.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 426.0ms\n",
      "Speed: 0.0ms preprocess, 426.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 457.3ms\n",
      "Speed: 0.0ms preprocess, 457.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 445.1ms\n",
      "Speed: 0.0ms preprocess, 445.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 444.4ms\n",
      "Speed: 0.0ms preprocess, 444.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 559.6ms\n",
      "Speed: 0.0ms preprocess, 559.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 457.7ms\n",
      "Speed: 5.3ms preprocess, 457.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 471.7ms\n",
      "Speed: 0.0ms preprocess, 471.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 456.6ms\n",
      "Speed: 0.0ms preprocess, 456.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 480.5ms\n",
      "Speed: 0.0ms preprocess, 480.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 439.7ms\n",
      "Speed: 0.0ms preprocess, 439.7ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 442.4ms\n",
      "Speed: 0.0ms preprocess, 442.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 472.5ms\n",
      "Speed: 0.0ms preprocess, 472.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 425.3ms\n",
      "Speed: 0.0ms preprocess, 425.3ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 459.7ms\n",
      "Speed: 0.0ms preprocess, 459.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 503.7ms\n",
      "Speed: 0.5ms preprocess, 503.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 542.1ms\n",
      "Speed: 2.2ms preprocess, 542.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 456.6ms\n",
      "Speed: 1.3ms preprocess, 456.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 540.7ms\n",
      "Speed: 2.9ms preprocess, 540.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 568.9ms\n",
      "Speed: 1.9ms preprocess, 568.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 549.4ms\n",
      "Speed: 0.0ms preprocess, 549.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 519.8ms\n",
      "Speed: 0.0ms preprocess, 519.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 472.1ms\n",
      "Speed: 0.0ms preprocess, 472.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 506.5ms\n",
      "Speed: 0.0ms preprocess, 506.5ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 521.8ms\n",
      "Speed: 0.0ms preprocess, 521.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 889.8ms\n",
      "Speed: 5.4ms preprocess, 889.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 586.3ms\n",
      "Speed: 4.3ms preprocess, 586.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 448.3ms\n",
      "Speed: 0.0ms preprocess, 448.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 483.2ms\n",
      "Speed: 0.0ms preprocess, 483.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 458.2ms\n",
      "Speed: 0.0ms preprocess, 458.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 506.0ms\n",
      "Speed: 0.0ms preprocess, 506.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 473.2ms\n",
      "Speed: 0.0ms preprocess, 473.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 460.0ms\n",
      "Speed: 0.0ms preprocess, 460.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 444.1ms\n",
      "Speed: 0.0ms preprocess, 444.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 489.4ms\n",
      "Speed: 0.0ms preprocess, 489.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 475.0ms\n",
      "Speed: 0.0ms preprocess, 475.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 488.9ms\n",
      "Speed: 0.0ms preprocess, 488.9ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 474.4ms\n",
      "Speed: 0.0ms preprocess, 474.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 472.6ms\n",
      "Speed: 0.0ms preprocess, 472.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 473.3ms\n",
      "Speed: 0.0ms preprocess, 473.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 504.0ms\n",
      "Speed: 0.0ms preprocess, 504.0ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 437.8ms\n",
      "Speed: 0.0ms preprocess, 437.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 476.2ms\n",
      "Speed: 0.0ms preprocess, 476.2ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 649.9ms\n",
      "Speed: 2.9ms preprocess, 649.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 570.3ms\n",
      "Speed: 0.0ms preprocess, 570.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 537.7ms\n",
      "Speed: 0.0ms preprocess, 537.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 537.6ms\n",
      "Speed: 0.0ms preprocess, 537.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 500.5ms\n",
      "Speed: 2.6ms preprocess, 500.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 462.4ms\n",
      "Speed: 0.0ms preprocess, 462.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 488.5ms\n",
      "Speed: 0.0ms preprocess, 488.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 441.8ms\n",
      "Speed: 0.0ms preprocess, 441.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 452.5ms\n",
      "Speed: 3.3ms preprocess, 452.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 532.4ms\n",
      "Speed: 4.5ms preprocess, 532.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 453.2ms\n",
      "Speed: 5.0ms preprocess, 453.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 479.2ms\n",
      "Speed: 3.2ms preprocess, 479.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 448.9ms\n",
      "Speed: 0.0ms preprocess, 448.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 500.6ms\n",
      "Speed: 4.2ms preprocess, 500.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 451.4ms\n",
      "Speed: 3.0ms preprocess, 451.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 484.7ms\n",
      "Speed: 3.8ms preprocess, 484.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 472.6ms\n",
      "Speed: 0.0ms preprocess, 472.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 493.1ms\n",
      "Speed: 0.0ms preprocess, 493.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 457.7ms\n",
      "Speed: 2.8ms preprocess, 457.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 471.8ms\n",
      "Speed: 0.0ms preprocess, 471.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 488.9ms\n",
      "Speed: 0.5ms preprocess, 488.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 489.4ms\n",
      "Speed: 0.0ms preprocess, 489.4ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 470.2ms\n",
      "Speed: 0.5ms preprocess, 470.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 441.0ms\n",
      "Speed: 0.0ms preprocess, 441.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 495.5ms\n",
      "Speed: 0.0ms preprocess, 495.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 473.5ms\n",
      "Speed: 0.0ms preprocess, 473.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 487.8ms\n",
      "Speed: 0.0ms preprocess, 487.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 486.9ms\n",
      "Speed: 0.0ms preprocess, 486.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 498.1ms\n",
      "Speed: 0.0ms preprocess, 498.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 507.5ms\n",
      "Speed: 0.0ms preprocess, 507.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 577.2ms\n",
      "Speed: 0.0ms preprocess, 577.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 520.3ms\n",
      "Speed: 2.6ms preprocess, 520.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 538.8ms\n",
      "Speed: 0.0ms preprocess, 538.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 538.2ms\n",
      "Speed: 0.0ms preprocess, 538.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 547.0ms\n",
      "Speed: 7.1ms preprocess, 547.0ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 662.0ms\n",
      "Speed: 2.8ms preprocess, 662.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 895.6ms\n",
      "Speed: 19.9ms preprocess, 895.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 566.0ms\n",
      "Speed: 0.0ms preprocess, 566.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 473.4ms\n",
      "Speed: 0.0ms preprocess, 473.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 471.4ms\n",
      "Speed: 0.5ms preprocess, 471.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 487.1ms\n",
      "Speed: 2.5ms preprocess, 487.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 503.5ms\n",
      "Speed: 0.0ms preprocess, 503.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 3 persons, 475.5ms\n",
      "Speed: 2.1ms preprocess, 475.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 473.9ms\n",
      "Speed: 0.0ms preprocess, 473.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 480.2ms\n",
      "Speed: 0.0ms preprocess, 480.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 458.2ms\n",
      "Speed: 0.0ms preprocess, 458.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 527.1ms\n",
      "Speed: 0.0ms preprocess, 527.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 549.1ms\n",
      "Speed: 2.2ms preprocess, 549.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 502.6ms\n",
      "Speed: 0.0ms preprocess, 502.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 494.4ms\n",
      "Speed: 0.0ms preprocess, 494.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 479.9ms\n",
      "Speed: 0.0ms preprocess, 479.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 477.8ms\n",
      "Speed: 6.4ms preprocess, 477.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 533.7ms\n",
      "Speed: 0.0ms preprocess, 533.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 909.5ms\n",
      "Speed: 6.0ms preprocess, 909.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 521.1ms\n",
      "Speed: 0.0ms preprocess, 521.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 455.1ms\n",
      "Speed: 0.0ms preprocess, 455.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 504.2ms\n",
      "Speed: 0.0ms preprocess, 504.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 520.5ms\n",
      "Speed: 0.0ms preprocess, 520.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 522.4ms\n",
      "Speed: 0.0ms preprocess, 522.4ms inference, 16.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 546.3ms\n",
      "Speed: 2.4ms preprocess, 546.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 520.9ms\n",
      "Speed: 1.0ms preprocess, 520.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 578.1ms\n",
      "Speed: 0.0ms preprocess, 578.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 502.5ms\n",
      "Speed: 2.3ms preprocess, 502.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 493.6ms\n",
      "Speed: 0.0ms preprocess, 493.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 486.7ms\n",
      "Speed: 0.0ms preprocess, 486.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 445.8ms\n",
      "Speed: 0.0ms preprocess, 445.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 600.1ms\n",
      "Speed: 0.0ms preprocess, 600.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 471.4ms\n",
      "Speed: 0.0ms preprocess, 471.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 412.8ms\n",
      "Speed: 0.0ms preprocess, 412.8ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 468.2ms\n",
      "Speed: 4.1ms preprocess, 468.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 455.4ms\n",
      "Speed: 4.1ms preprocess, 455.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 464.6ms\n",
      "Speed: 0.0ms preprocess, 464.6ms inference, 9.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 486.9ms\n",
      "Speed: 4.8ms preprocess, 486.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 518.6ms\n",
      "Speed: 4.1ms preprocess, 518.6ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 480.8ms\n",
      "Speed: 0.0ms preprocess, 480.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 565.2ms\n",
      "Speed: 0.0ms preprocess, 565.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 454.9ms\n",
      "Speed: 2.6ms preprocess, 454.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 490.3ms\n",
      "Speed: 0.0ms preprocess, 490.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 469.7ms\n",
      "Speed: 3.9ms preprocess, 469.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 505.7ms\n",
      "Speed: 2.3ms preprocess, 505.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 471.0ms\n",
      "Speed: 1.8ms preprocess, 471.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 513.3ms\n",
      "Speed: 0.0ms preprocess, 513.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 492.8ms\n",
      "Speed: 0.0ms preprocess, 492.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 489.5ms\n",
      "Speed: 5.8ms preprocess, 489.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 500.9ms\n",
      "Speed: 4.8ms preprocess, 500.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 596.9ms\n",
      "Speed: 1.0ms preprocess, 596.9ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 605.3ms\n",
      "Speed: 2.1ms preprocess, 605.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 609.0ms\n",
      "Speed: 5.1ms preprocess, 609.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 525.1ms\n",
      "Speed: 2.0ms preprocess, 525.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 565.6ms\n",
      "Speed: 5.1ms preprocess, 565.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 575.0ms\n",
      "Speed: 2.9ms preprocess, 575.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 504.2ms\n",
      "Speed: 2.3ms preprocess, 504.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 458.9ms\n",
      "Speed: 0.0ms preprocess, 458.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 483.0ms\n",
      "Speed: 0.0ms preprocess, 483.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 471.7ms\n",
      "Speed: 0.0ms preprocess, 471.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 461.0ms\n",
      "Speed: 0.0ms preprocess, 461.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 473.4ms\n",
      "Speed: 0.0ms preprocess, 473.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 476.5ms\n",
      "Speed: 2.5ms preprocess, 476.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 441.7ms\n",
      "Speed: 0.0ms preprocess, 441.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 469.2ms\n",
      "Speed: 1.6ms preprocess, 469.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 514.7ms\n",
      "Speed: 0.0ms preprocess, 514.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 448.8ms\n",
      "Speed: 4.2ms preprocess, 448.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 527.3ms\n",
      "Speed: 3.0ms preprocess, 527.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 476.5ms\n",
      "Speed: 4.0ms preprocess, 476.5ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict3\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m success,frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m---> 18\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     annotate_frame \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m     22\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOLO8 Interface\u001b[39m\u001b[38;5;124m\"\u001b[39m,annotate_frame)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\model.py:96\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\model.py:238\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 253\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:133\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference\u001b[39m(\u001b[38;5;28mself\u001b[39m, im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    131\u001b[0m     visualize \u001b[38;5;241m=\u001b[39m increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem,\n\u001b[0;32m    132\u001b[0m                                mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:333\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    330\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize) \u001b[38;5;28;01mif\u001b[39;00m augment \u001b[38;5;129;01mor\u001b[39;00m visualize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\nn\\tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "#model = YOLO('yolov8n.pt')\n",
    "model = YOLO('yolov8s-pose.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = 0\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# loop through video frame\n",
    "while cap.isOpened():\n",
    "    success,frame = cap.read()\n",
    "    \n",
    "    if success:\n",
    "        result = model(frame, save=True)\n",
    "        \n",
    "        annotate_frame = result[0].plot()\n",
    "        \n",
    "        cv2.imshow(\"YOLO8 Interface\",annotate_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb28bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "Ultralytics YOLOv8.0.175  Python-3.9.17 torch-2.0.1+cpu CPU (Intel Core(TM) i5-8365U 1.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.yaml, data=D:/Sitting pose/coco8-pose.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\BAPS\\runs\\pose\\train6\n",
      "Overriding model.yaml nc=1 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1036519  ultralytics.nn.modules.head.Pose             [4, [17, 3], [64, 128, 256]]  \n",
      "YOLOv8n-pose summary: 250 layers, 3296055 parameters, 3296039 gradients\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Sitting pose\\labels\\train... 28 images, 0 backgrounds, 0 corrupt: 100%|| 28/28 [00:00<00:0\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Sitting pose\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Sitting pose\\labels\\val... 5 images, 0 backgrounds, 0 corrupt: 100%|| 5/5 [00:00<00:00, 1973\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Sitting pose\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\BAPS\\runs\\pose\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\train6\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 must be greater than or equal to x0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.933      2.949     0.4754      3.225       2.48         37        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.747        0.5      0.954      0.312      0.747        0.5      0.954       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G      1.734      3.344     0.5278      3.123      2.221         34        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5          1      0.474      0.913      0.341          1      0.474      0.913      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G      1.557      2.866     0.4488      3.116      2.031         32        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5          1      0.487      0.954      0.455          1      0.487      0.954      0.847\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50         0G      1.408      2.234     0.4155      2.878       1.82         38        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.427      0.667      0.913      0.577      0.427      0.667      0.913       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50         0G      1.316      2.548      0.423      2.735      1.739         31        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.546          1      0.871      0.639      0.546          1      0.871      0.716\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50         0G       1.19      1.883     0.3614      2.625      1.689         31        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5       0.56          1      0.871      0.608       0.56          1      0.871      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50         0G      1.223      1.729     0.3886      2.224      1.709         35        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.552          1      0.746      0.475      0.552          1      0.746      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50         0G      1.161      1.987     0.3872      2.129      1.655         28        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.649      0.948      0.787      0.511      0.649      0.948      0.787      0.503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50         0G      1.202      1.532     0.3107      1.972      1.655         35        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.793       0.75       0.87      0.602      0.793       0.75       0.87        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50         0G      1.268      1.754     0.3512      2.006      1.777         29        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.438       0.75       0.87      0.659      0.438       0.75       0.87      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50         0G      1.093      1.563     0.3671      1.834      1.623         30        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.462       0.75       0.87      0.631      0.462       0.75       0.87      0.674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50         0G      1.235      2.022     0.3253      1.958      1.641         32        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.755      0.583      0.829      0.593      0.755      0.583      0.829      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50         0G      1.085      1.506     0.3495      1.673      1.534         36        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.622      0.937      0.787      0.602      0.622      0.937      0.787      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50         0G      1.166      1.451     0.3203      1.767      1.637         37        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.661      0.983      0.787      0.581      0.661      0.983      0.787      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50         0G      1.181      2.306     0.3504      1.796      1.559         39        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.689          1      0.829      0.642      0.689          1      0.829      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50         0G      1.226      1.986     0.3662      1.882      1.716         29        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.802          1      0.912      0.712      0.802          1      0.912      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50         0G      1.184      1.824     0.3514      1.855      1.624         33        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.805      0.984      0.912      0.691      0.805      0.984      0.912      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/50         0G      1.132       2.17     0.3181      1.774      1.578         36        640: 100%|| 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.782      0.887      0.912      0.652      0.782      0.887      0.912      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/50         0G      1.255      1.826     0.3703      1.796      1.702         36        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.687          1      0.995      0.735      0.687          1      0.995      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/50         0G      1.029      2.013     0.3485      1.691      1.495         34        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.696          1      0.995      0.737      0.696          1      0.995       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/50         0G      1.015      1.941     0.3436      1.747       1.56         25        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.715          1      0.995      0.787      0.715          1      0.995      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/50         0G      1.093      2.236     0.3588      1.821      1.574         32        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.731          1      0.912      0.739      0.731          1      0.912      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/50         0G      1.106      2.446     0.3752      1.705      1.665         29        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.734          1      0.912      0.766      0.734          1      0.912      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/50         0G      1.055      1.862     0.3327      1.589       1.51         38        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.709          1      0.912      0.752      0.709          1      0.912      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/50         0G      1.065      1.599     0.2811      1.603       1.52         31        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.742          1      0.912      0.716      0.742          1      0.912      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/50         0G      1.085      1.882     0.3376      1.512      1.522         34        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.667          1      0.912      0.689      0.667          1      0.912      0.745\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/50         0G      1.057       1.95     0.3368      1.454      1.511         42        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.953      0.967      0.995      0.736      0.953      0.967      0.995      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/50         0G      1.059      1.803     0.3257      1.591      1.588         25        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.953      0.967      0.995      0.736      0.953      0.967      0.995      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/50         0G      1.046      1.623     0.3345      1.518      1.493         43        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.966          1      0.995      0.763      0.966          1      0.995      0.842\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/50         0G      1.002      1.842      0.306      1.399      1.478         36        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5       0.97          1      0.995      0.843       0.97          1      0.995      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/50         0G     0.9894      1.809     0.3429      1.496      1.503         37        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5       0.97          1      0.995      0.843       0.97          1      0.995      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/50         0G      1.022      2.084     0.3344      1.528      1.528         32        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.896      0.984      0.995      0.891      0.896      0.984      0.995      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/50         0G     0.9689      1.813     0.3712      1.618      1.433         35        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.943          1      0.995      0.839      0.943          1      0.995      0.763\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/50         0G     0.9961      1.787     0.3153      1.465      1.479         34        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.943          1      0.995      0.839      0.943          1      0.995      0.763\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/50         0G     0.9492      1.902      0.353      1.422      1.469         38        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.981          1      0.995      0.839      0.981          1      0.995      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/50         0G      1.051      1.766     0.3116      1.492        1.5         38        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.977          1      0.995      0.864      0.977          1      0.995      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/50         0G      0.976      1.941     0.3283      1.502      1.473         34        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.977          1      0.995      0.864      0.977          1      0.995      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/50         0G     0.9653      1.634     0.3572      1.186      1.401         41        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.969          1      0.995      0.847      0.969          1      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/50         0G      0.995       2.15     0.2931      1.392      1.507         37        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.954          1      0.995      0.838      0.954          1      0.995      0.921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/50         0G     0.9852      1.572     0.3247      1.354      1.424         33        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.954          1      0.995      0.838      0.954          1      0.995      0.921\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      41/50         0G     0.9098      1.176     0.3321      1.841      1.578         13        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.966          1      0.995      0.813      0.966          1      0.995      0.923\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      42/50         0G      0.963      1.341     0.3526      1.697      1.642         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.977          1      0.995      0.743      0.977          1      0.995      0.937\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      43/50         0G     0.9265      1.188     0.3554      1.645       1.61         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.977          1      0.995      0.743      0.977          1      0.995      0.937\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      44/50         0G     0.8026       1.09     0.3556      1.588      1.486         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.977          1      0.995      0.715      0.977          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      45/50         0G     0.8185       1.23     0.3557      1.608      1.575         13        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.977          1      0.995      0.715      0.977          1      0.995      0.888\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      46/50         0G     0.7648     0.9536     0.3195      1.492      1.475         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.968          1      0.995      0.721      0.968          1      0.995      0.921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      47/50         0G     0.9344      1.027     0.3253      1.566      1.635         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.968          1      0.995      0.721      0.968          1      0.995      0.921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      48/50         0G     0.9297      1.311     0.3288      1.559      1.716         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.962          1      0.995       0.72      0.962          1      0.995      0.921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      49/50         0G     0.7519     0.9707     0.2988      1.457      1.507         13        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.962          1      0.995       0.72      0.962          1      0.995      0.921\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      50/50         0G     0.7814      1.052      0.328      1.496      1.525         12        640: 100%|| 2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.965          1      0.995      0.736      0.965          1      0.995      0.903\n",
      "\n",
      "50 epochs completed in 0.441 hours.\n",
      "Optimizer stripped from C:\\Users\\BAPS\\runs\\pose\\train6\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from C:\\Users\\BAPS\\runs\\pose\\train6\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating C:\\Users\\BAPS\\runs\\pose\\train6\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.175  Python-3.9.17 torch-2.0.1+cpu CPU (Intel Core(TM) i5-8365U 1.60GHz)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3290549 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP\n",
      "                   all          5          5      0.954          1      0.995      0.838      0.954          1      0.995      0.921\n",
      "     Good Sitting Pose          5          3      0.917          1      0.995       0.78      0.917          1      0.995      0.895\n",
      "      Bad Sitting Pose          5          2       0.99          1      0.995      0.896       0.99          1      0.995      0.946\n",
      "Speed: 2.5ms preprocess, 394.1ms inference, 0.0ms loss, 7.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# custome Model \n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n-pose.pt')  # load a pretrained model (recommended for training)\n",
    "model = YOLO('yolov8n-pose.yaml').load('yolov8n-pose.pt')  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=r'D:/Sitting pose/coco8-pose.yaml', epochs=50, imgsz=640, lr0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate trained YOLOv8n-pose model accuracy on the COCO128-pose dataset\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.pt')  # load an official model\n",
    "model = YOLO('path/to/best.pt')  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff5e5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Sitting pose\\g7.jpg: 640x512 1 Good Sitting Pose, 438.3ms\n",
      "Speed: 6.5ms preprocess, 438.3ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\pose\\train6\\weights\\best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(r'D:\\Sitting pose\\g7.jpg', save=True, conf=0.5)  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a881874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 408.3ms\n",
      "video 1/1 (2/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 209.5ms\n",
      "video 1/1 (3/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.6ms\n",
      "video 1/1 (4/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 243.6ms\n",
      "video 1/1 (5/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.6ms\n",
      "video 1/1 (6/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.7ms\n",
      "video 1/1 (7/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 199.8ms\n",
      "video 1/1 (8/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.9ms\n",
      "video 1/1 (9/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 208.8ms\n",
      "video 1/1 (10/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.2ms\n",
      "video 1/1 (11/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 206.9ms\n",
      "video 1/1 (12/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.0ms\n",
      "video 1/1 (13/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.0ms\n",
      "video 1/1 (14/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.2ms\n",
      "video 1/1 (15/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.3ms\n",
      "video 1/1 (16/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.5ms\n",
      "video 1/1 (17/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.7ms\n",
      "video 1/1 (18/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 208.0ms\n",
      "video 1/1 (19/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 205.6ms\n",
      "video 1/1 (20/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.3ms\n",
      "video 1/1 (21/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.7ms\n",
      "video 1/1 (22/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.9ms\n",
      "video 1/1 (23/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.4ms\n",
      "video 1/1 (24/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 212.3ms\n",
      "video 1/1 (25/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.0ms\n",
      "video 1/1 (26/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.9ms\n",
      "video 1/1 (27/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.8ms\n",
      "video 1/1 (28/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.5ms\n",
      "video 1/1 (29/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.5ms\n",
      "video 1/1 (30/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.4ms\n",
      "video 1/1 (31/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 191.4ms\n",
      "video 1/1 (32/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.1ms\n",
      "video 1/1 (33/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 217.6ms\n",
      "video 1/1 (34/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.0ms\n",
      "video 1/1 (35/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 241.9ms\n",
      "video 1/1 (36/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.5ms\n",
      "video 1/1 (37/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.9ms\n",
      "video 1/1 (38/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.0ms\n",
      "video 1/1 (39/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.1ms\n",
      "video 1/1 (40/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.7ms\n",
      "video 1/1 (41/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 207.8ms\n",
      "video 1/1 (42/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 217.0ms\n",
      "video 1/1 (43/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.8ms\n",
      "video 1/1 (44/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.1ms\n",
      "video 1/1 (45/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.9ms\n",
      "video 1/1 (46/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.7ms\n",
      "video 1/1 (47/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 216.0ms\n",
      "video 1/1 (48/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.3ms\n",
      "video 1/1 (49/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.4ms\n",
      "video 1/1 (50/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.6ms\n",
      "video 1/1 (51/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.9ms\n",
      "video 1/1 (52/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 206.4ms\n",
      "video 1/1 (53/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.0ms\n",
      "video 1/1 (54/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 205.1ms\n",
      "video 1/1 (55/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 203.4ms\n",
      "video 1/1 (56/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.8ms\n",
      "video 1/1 (57/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 202.5ms\n",
      "video 1/1 (58/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.5ms\n",
      "video 1/1 (59/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 200.5ms\n",
      "video 1/1 (60/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 239.1ms\n",
      "video 1/1 (61/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 190.3ms\n",
      "video 1/1 (62/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 216.5ms\n",
      "video 1/1 (63/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.4ms\n",
      "video 1/1 (64/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 198.5ms\n",
      "video 1/1 (65/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.1ms\n",
      "video 1/1 (66/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 216.1ms\n",
      "video 1/1 (67/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.8ms\n",
      "video 1/1 (68/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 195.8ms\n",
      "video 1/1 (69/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 217.3ms\n",
      "video 1/1 (70/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.6ms\n",
      "video 1/1 (71/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 210.2ms\n",
      "video 1/1 (72/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.9ms\n",
      "video 1/1 (73/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.3ms\n",
      "video 1/1 (74/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.7ms\n",
      "video 1/1 (75/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 216.2ms\n",
      "video 1/1 (76/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 197.7ms\n",
      "video 1/1 (77/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.4ms\n",
      "video 1/1 (78/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.4ms\n",
      "video 1/1 (79/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.7ms\n",
      "video 1/1 (80/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.2ms\n",
      "video 1/1 (81/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.5ms\n",
      "video 1/1 (82/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.2ms\n",
      "video 1/1 (83/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.4ms\n",
      "video 1/1 (84/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.0ms\n",
      "video 1/1 (85/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.2ms\n",
      "video 1/1 (86/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.8ms\n",
      "video 1/1 (87/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.2ms\n",
      "video 1/1 (88/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.3ms\n",
      "video 1/1 (89/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.2ms\n",
      "video 1/1 (90/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 230.4ms\n",
      "video 1/1 (91/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.1ms\n",
      "video 1/1 (92/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.5ms\n",
      "video 1/1 (93/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.6ms\n",
      "video 1/1 (94/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.8ms\n",
      "video 1/1 (95/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 196.4ms\n",
      "video 1/1 (96/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 202.1ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (97/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.1ms\n",
      "video 1/1 (98/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.2ms\n",
      "video 1/1 (99/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.9ms\n",
      "video 1/1 (100/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.1ms\n",
      "video 1/1 (101/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 199.8ms\n",
      "video 1/1 (102/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 204.4ms\n",
      "video 1/1 (103/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.2ms\n",
      "video 1/1 (104/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.0ms\n",
      "video 1/1 (105/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 230.7ms\n",
      "video 1/1 (106/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.3ms\n",
      "video 1/1 (107/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.6ms\n",
      "video 1/1 (108/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.5ms\n",
      "video 1/1 (109/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.1ms\n",
      "video 1/1 (110/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.8ms\n",
      "video 1/1 (111/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.9ms\n",
      "video 1/1 (112/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.7ms\n",
      "video 1/1 (113/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.4ms\n",
      "video 1/1 (114/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.0ms\n",
      "video 1/1 (115/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.8ms\n",
      "video 1/1 (116/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 210.9ms\n",
      "video 1/1 (117/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 240.0ms\n",
      "video 1/1 (118/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.7ms\n",
      "video 1/1 (119/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.3ms\n",
      "video 1/1 (120/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 217.8ms\n",
      "video 1/1 (121/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.6ms\n",
      "video 1/1 (122/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 230.1ms\n",
      "video 1/1 (123/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.8ms\n",
      "video 1/1 (124/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.3ms\n",
      "video 1/1 (125/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 210.1ms\n",
      "video 1/1 (126/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 185.1ms\n",
      "video 1/1 (127/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 197.2ms\n",
      "video 1/1 (128/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.1ms\n",
      "video 1/1 (129/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 202.9ms\n",
      "video 1/1 (130/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 216.1ms\n",
      "video 1/1 (131/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.9ms\n",
      "video 1/1 (132/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 192.7ms\n",
      "video 1/1 (133/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.1ms\n",
      "video 1/1 (134/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.5ms\n",
      "video 1/1 (135/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.0ms\n",
      "video 1/1 (136/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 168.5ms\n",
      "video 1/1 (137/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.1ms\n",
      "video 1/1 (138/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.0ms\n",
      "video 1/1 (139/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.9ms\n",
      "video 1/1 (140/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 208.3ms\n",
      "video 1/1 (141/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 177.2ms\n",
      "video 1/1 (142/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.5ms\n",
      "video 1/1 (143/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 380.7ms\n",
      "video 1/1 (144/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 139.1ms\n",
      "video 1/1 (145/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 184.8ms\n",
      "video 1/1 (146/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 170.3ms\n",
      "video 1/1 (147/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 144.5ms\n",
      "video 1/1 (148/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 189.4ms\n",
      "video 1/1 (149/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 159.7ms\n",
      "video 1/1 (150/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.9ms\n",
      "video 1/1 (151/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 183.3ms\n",
      "video 1/1 (152/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 186.6ms\n",
      "video 1/1 (153/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 216.1ms\n",
      "video 1/1 (154/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 186.8ms\n",
      "video 1/1 (155/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.1ms\n",
      "video 1/1 (156/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.2ms\n",
      "video 1/1 (157/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 193.4ms\n",
      "video 1/1 (158/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.1ms\n",
      "video 1/1 (159/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.6ms\n",
      "video 1/1 (160/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.1ms\n",
      "video 1/1 (161/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.1ms\n",
      "video 1/1 (162/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.6ms\n",
      "video 1/1 (163/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.3ms\n",
      "video 1/1 (164/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 198.4ms\n",
      "video 1/1 (165/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.6ms\n",
      "video 1/1 (166/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.9ms\n",
      "video 1/1 (167/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 205.0ms\n",
      "video 1/1 (168/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.9ms\n",
      "video 1/1 (169/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 204.7ms\n",
      "video 1/1 (170/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.6ms\n",
      "video 1/1 (171/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.3ms\n",
      "video 1/1 (172/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.2ms\n",
      "video 1/1 (173/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.7ms\n",
      "video 1/1 (174/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 174.7ms\n",
      "video 1/1 (175/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 153.9ms\n",
      "video 1/1 (176/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.5ms\n",
      "video 1/1 (177/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 142.1ms\n",
      "video 1/1 (178/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 166.5ms\n",
      "video 1/1 (179/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 168.3ms\n",
      "video 1/1 (180/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 166.9ms\n",
      "video 1/1 (181/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 172.4ms\n",
      "video 1/1 (182/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.0ms\n",
      "video 1/1 (183/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.9ms\n",
      "video 1/1 (184/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.2ms\n",
      "video 1/1 (185/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 205.4ms\n",
      "video 1/1 (186/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 210.7ms\n",
      "video 1/1 (187/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.6ms\n",
      "video 1/1 (188/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 203.9ms\n",
      "video 1/1 (189/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.4ms\n",
      "video 1/1 (190/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.8ms\n",
      "video 1/1 (191/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.2ms\n",
      "video 1/1 (192/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 177.9ms\n",
      "video 1/1 (193/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.7ms\n",
      "video 1/1 (194/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.8ms\n",
      "video 1/1 (195/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 230.3ms\n",
      "video 1/1 (196/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.4ms\n",
      "video 1/1 (197/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.9ms\n",
      "video 1/1 (198/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (199/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.4ms\n",
      "video 1/1 (200/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 242.3ms\n",
      "video 1/1 (201/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 246.5ms\n",
      "video 1/1 (202/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 202.9ms\n",
      "video 1/1 (203/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.2ms\n",
      "video 1/1 (204/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 205.3ms\n",
      "video 1/1 (205/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.2ms\n",
      "video 1/1 (206/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.2ms\n",
      "video 1/1 (207/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 178.4ms\n",
      "video 1/1 (208/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.6ms\n",
      "video 1/1 (209/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.8ms\n",
      "video 1/1 (210/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 243.3ms\n",
      "video 1/1 (211/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.0ms\n",
      "video 1/1 (212/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.7ms\n",
      "video 1/1 (213/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.5ms\n",
      "video 1/1 (214/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.9ms\n",
      "video 1/1 (215/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.1ms\n",
      "video 1/1 (216/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.9ms\n",
      "video 1/1 (217/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 208.6ms\n",
      "video 1/1 (218/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 208.7ms\n",
      "video 1/1 (219/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.3ms\n",
      "video 1/1 (220/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 241.2ms\n",
      "video 1/1 (221/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 176.9ms\n",
      "video 1/1 (222/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.9ms\n",
      "video 1/1 (223/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 169.4ms\n",
      "video 1/1 (224/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 203.6ms\n",
      "video 1/1 (225/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.0ms\n",
      "video 1/1 (226/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.2ms\n",
      "video 1/1 (227/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.4ms\n",
      "video 1/1 (228/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.5ms\n",
      "video 1/1 (229/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.3ms\n",
      "video 1/1 (230/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.2ms\n",
      "video 1/1 (231/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.2ms\n",
      "video 1/1 (232/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.5ms\n",
      "video 1/1 (233/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.8ms\n",
      "video 1/1 (234/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.8ms\n",
      "video 1/1 (235/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 238.3ms\n",
      "video 1/1 (236/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 240.1ms\n",
      "video 1/1 (237/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.7ms\n",
      "video 1/1 (238/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.8ms\n",
      "video 1/1 (239/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.2ms\n",
      "video 1/1 (240/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.3ms\n",
      "video 1/1 (241/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 279.8ms\n",
      "video 1/1 (242/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 292.8ms\n",
      "video 1/1 (243/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 160.4ms\n",
      "video 1/1 (244/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 197.0ms\n",
      "video 1/1 (245/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 207.0ms\n",
      "video 1/1 (246/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 189.0ms\n",
      "video 1/1 (247/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.3ms\n",
      "video 1/1 (248/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.3ms\n",
      "video 1/1 (249/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 190.9ms\n",
      "video 1/1 (250/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.6ms\n",
      "video 1/1 (251/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.7ms\n",
      "video 1/1 (252/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 138.9ms\n",
      "video 1/1 (253/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.5ms\n",
      "video 1/1 (254/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.4ms\n",
      "video 1/1 (255/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.4ms\n",
      "video 1/1 (256/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.3ms\n",
      "video 1/1 (257/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.2ms\n",
      "video 1/1 (258/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 141.4ms\n",
      "video 1/1 (259/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 146.0ms\n",
      "video 1/1 (260/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.3ms\n",
      "video 1/1 (261/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.9ms\n",
      "video 1/1 (262/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.3ms\n",
      "video 1/1 (263/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.3ms\n",
      "video 1/1 (264/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.4ms\n",
      "video 1/1 (265/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.8ms\n",
      "video 1/1 (266/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 175.0ms\n",
      "video 1/1 (267/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.1ms\n",
      "video 1/1 (268/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 142.8ms\n",
      "video 1/1 (269/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 182.8ms\n",
      "video 1/1 (270/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 179.6ms\n",
      "video 1/1 (271/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 135.0ms\n",
      "video 1/1 (272/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.6ms\n",
      "video 1/1 (273/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 177.5ms\n",
      "video 1/1 (274/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.5ms\n",
      "video 1/1 (275/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 185.2ms\n",
      "video 1/1 (276/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.7ms\n",
      "video 1/1 (277/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 208.8ms\n",
      "video 1/1 (278/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.6ms\n",
      "video 1/1 (279/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 206.2ms\n",
      "video 1/1 (280/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 238.8ms\n",
      "video 1/1 (281/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.2ms\n",
      "video 1/1 (282/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.8ms\n",
      "video 1/1 (283/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.3ms\n",
      "video 1/1 (284/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 217.3ms\n",
      "video 1/1 (285/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 237.7ms\n",
      "video 1/1 (286/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 186.2ms\n",
      "video 1/1 (287/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 188.0ms\n",
      "video 1/1 (288/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.8ms\n",
      "video 1/1 (289/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.7ms\n",
      "video 1/1 (290/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 249.1ms\n",
      "video 1/1 (291/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.8ms\n",
      "video 1/1 (292/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.9ms\n",
      "video 1/1 (293/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.4ms\n",
      "video 1/1 (294/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.9ms\n",
      "video 1/1 (295/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.6ms\n",
      "video 1/1 (296/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.9ms\n",
      "video 1/1 (297/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 209.1ms\n",
      "video 1/1 (298/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.1ms\n",
      "video 1/1 (299/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 173.2ms\n",
      "video 1/1 (300/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 258.9ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (301/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 200.3ms\n",
      "video 1/1 (302/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 268.4ms\n",
      "video 1/1 (303/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 352.1ms\n",
      "video 1/1 (304/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.9ms\n",
      "video 1/1 (305/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 130.8ms\n",
      "video 1/1 (306/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 189.4ms\n",
      "video 1/1 (307/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.2ms\n",
      "video 1/1 (308/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 154.7ms\n",
      "video 1/1 (309/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.5ms\n",
      "video 1/1 (310/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 174.2ms\n",
      "video 1/1 (311/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 181.0ms\n",
      "video 1/1 (312/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.0ms\n",
      "video 1/1 (313/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.0ms\n",
      "video 1/1 (314/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.8ms\n",
      "video 1/1 (315/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.7ms\n",
      "video 1/1 (316/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.0ms\n",
      "video 1/1 (317/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.0ms\n",
      "video 1/1 (318/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 206.4ms\n",
      "video 1/1 (319/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.6ms\n",
      "video 1/1 (320/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 195.0ms\n",
      "video 1/1 (321/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.9ms\n",
      "video 1/1 (322/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 172.9ms\n",
      "video 1/1 (323/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 176.2ms\n",
      "video 1/1 (324/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.8ms\n",
      "video 1/1 (325/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.1ms\n",
      "video 1/1 (326/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 195.9ms\n",
      "video 1/1 (327/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 180.0ms\n",
      "video 1/1 (328/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 146.2ms\n",
      "video 1/1 (329/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.9ms\n",
      "video 1/1 (330/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 243.6ms\n",
      "video 1/1 (331/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 207.7ms\n",
      "video 1/1 (332/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.8ms\n",
      "video 1/1 (333/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 205.1ms\n",
      "video 1/1 (334/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.4ms\n",
      "video 1/1 (335/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 189.6ms\n",
      "video 1/1 (336/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 213.2ms\n",
      "video 1/1 (337/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 207.5ms\n",
      "video 1/1 (338/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.7ms\n",
      "video 1/1 (339/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.1ms\n",
      "video 1/1 (340/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.1ms\n",
      "video 1/1 (341/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 210.2ms\n",
      "video 1/1 (342/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.8ms\n",
      "video 1/1 (343/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.8ms\n",
      "video 1/1 (344/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.9ms\n",
      "video 1/1 (345/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 198.9ms\n",
      "video 1/1 (346/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 182.7ms\n",
      "video 1/1 (347/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 193.5ms\n",
      "video 1/1 (348/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 142.6ms\n",
      "video 1/1 (349/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.4ms\n",
      "video 1/1 (350/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 230.9ms\n",
      "video 1/1 (351/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.7ms\n",
      "video 1/1 (352/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.7ms\n",
      "video 1/1 (353/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 217.7ms\n",
      "video 1/1 (354/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 237.3ms\n",
      "video 1/1 (355/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.2ms\n",
      "video 1/1 (356/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 212.5ms\n",
      "video 1/1 (357/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 853.8ms\n",
      "video 1/1 (358/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 197.3ms\n",
      "video 1/1 (359/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 206.6ms\n",
      "video 1/1 (360/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.6ms\n",
      "video 1/1 (361/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.0ms\n",
      "video 1/1 (362/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 212.6ms\n",
      "video 1/1 (363/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.0ms\n",
      "video 1/1 (364/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.9ms\n",
      "video 1/1 (365/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.6ms\n",
      "video 1/1 (366/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 218.9ms\n",
      "video 1/1 (367/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 184.9ms\n",
      "video 1/1 (368/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 214.0ms\n",
      "video 1/1 (369/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 177.4ms\n",
      "video 1/1 (370/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.3ms\n",
      "video 1/1 (371/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.2ms\n",
      "video 1/1 (372/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.3ms\n",
      "video 1/1 (373/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 229.6ms\n",
      "video 1/1 (374/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 119.4ms\n",
      "video 1/1 (375/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 128.9ms\n",
      "video 1/1 (376/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.6ms\n",
      "video 1/1 (377/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 184.2ms\n",
      "video 1/1 (378/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 220.8ms\n",
      "video 1/1 (379/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 201.9ms\n",
      "video 1/1 (380/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.2ms\n",
      "video 1/1 (381/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 271.7ms\n",
      "video 1/1 (382/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 167.5ms\n",
      "video 1/1 (383/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 176.9ms\n",
      "video 1/1 (384/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 212.5ms\n",
      "video 1/1 (385/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.5ms\n",
      "video 1/1 (386/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.4ms\n",
      "video 1/1 (387/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.9ms\n",
      "video 1/1 (388/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.3ms\n",
      "video 1/1 (389/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 212.3ms\n",
      "video 1/1 (390/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.1ms\n",
      "video 1/1 (391/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.9ms\n",
      "video 1/1 (392/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 237.4ms\n",
      "video 1/1 (393/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.0ms\n",
      "video 1/1 (394/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.8ms\n",
      "video 1/1 (395/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 243.5ms\n",
      "video 1/1 (396/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 243.5ms\n",
      "video 1/1 (397/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.3ms\n",
      "video 1/1 (398/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 250.5ms\n",
      "video 1/1 (399/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.3ms\n",
      "video 1/1 (400/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.2ms\n",
      "video 1/1 (401/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.8ms\n",
      "video 1/1 (402/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.3ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (403/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.3ms\n",
      "video 1/1 (404/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 189.5ms\n",
      "video 1/1 (405/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.0ms\n",
      "video 1/1 (406/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.9ms\n",
      "video 1/1 (407/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 196.3ms\n",
      "video 1/1 (408/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.2ms\n",
      "video 1/1 (409/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.4ms\n",
      "video 1/1 (410/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.9ms\n",
      "video 1/1 (411/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 230.2ms\n",
      "video 1/1 (412/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 211.3ms\n",
      "video 1/1 (413/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.9ms\n",
      "video 1/1 (414/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.8ms\n",
      "video 1/1 (415/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.9ms\n",
      "video 1/1 (416/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.3ms\n",
      "video 1/1 (417/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.0ms\n",
      "video 1/1 (418/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.1ms\n",
      "video 1/1 (419/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.0ms\n",
      "video 1/1 (420/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.9ms\n",
      "video 1/1 (421/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.4ms\n",
      "video 1/1 (422/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 237.9ms\n",
      "video 1/1 (423/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 207.1ms\n",
      "video 1/1 (424/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 239.1ms\n",
      "video 1/1 (425/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 242.0ms\n",
      "video 1/1 (426/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 212.1ms\n",
      "video 1/1 (427/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 228.4ms\n",
      "video 1/1 (428/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.0ms\n",
      "video 1/1 (429/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 223.4ms\n",
      "video 1/1 (430/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 193.7ms\n",
      "video 1/1 (431/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 231.6ms\n",
      "video 1/1 (432/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 226.9ms\n",
      "video 1/1 (433/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 232.7ms\n",
      "video 1/1 (434/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 238.3ms\n",
      "video 1/1 (435/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 207.8ms\n",
      "video 1/1 (436/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 224.2ms\n",
      "video 1/1 (437/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 200.9ms\n",
      "video 1/1 (438/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 154.9ms\n",
      "video 1/1 (439/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 248.3ms\n",
      "video 1/1 (440/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 285.1ms\n",
      "video 1/1 (441/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 126.6ms\n",
      "video 1/1 (442/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 234.8ms\n",
      "video 1/1 (443/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.6ms\n",
      "video 1/1 (444/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 215.9ms\n",
      "video 1/1 (445/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.0ms\n",
      "video 1/1 (446/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.7ms\n",
      "video 1/1 (447/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 235.2ms\n",
      "video 1/1 (448/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 245.0ms\n",
      "video 1/1 (449/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 225.9ms\n",
      "video 1/1 (450/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.9ms\n",
      "video 1/1 (451/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 236.4ms\n",
      "video 1/1 (452/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 245.1ms\n",
      "video 1/1 (453/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 219.6ms\n",
      "video 1/1 (454/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 222.1ms\n",
      "video 1/1 (455/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 221.0ms\n",
      "video 1/1 (456/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.9ms\n",
      "video 1/1 (457/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 233.9ms\n",
      "video 1/1 (458/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 227.4ms\n",
      "video 1/1 (459/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 176.4ms\n",
      "video 1/1 (460/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 132.7ms\n",
      "video 1/1 (461/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.9ms\n",
      "video 1/1 (462/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 132.3ms\n",
      "video 1/1 (463/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 166.5ms\n",
      "video 1/1 (464/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 165.4ms\n",
      "video 1/1 (465/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.9ms\n",
      "video 1/1 (466/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.8ms\n",
      "video 1/1 (467/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.7ms\n",
      "video 1/1 (468/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 156.3ms\n",
      "video 1/1 (469/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.8ms\n",
      "video 1/1 (470/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.0ms\n",
      "video 1/1 (471/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.2ms\n",
      "video 1/1 (472/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.1ms\n",
      "video 1/1 (473/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.8ms\n",
      "video 1/1 (474/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.8ms\n",
      "video 1/1 (475/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.3ms\n",
      "video 1/1 (476/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.4ms\n",
      "video 1/1 (477/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 140.1ms\n",
      "video 1/1 (478/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.0ms\n",
      "video 1/1 (479/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.7ms\n",
      "video 1/1 (480/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 159.4ms\n",
      "video 1/1 (481/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.0ms\n",
      "video 1/1 (482/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 147.2ms\n",
      "video 1/1 (483/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 138.3ms\n",
      "video 1/1 (484/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.3ms\n",
      "video 1/1 (485/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 132.8ms\n",
      "video 1/1 (486/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.4ms\n",
      "video 1/1 (487/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.2ms\n",
      "video 1/1 (488/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.2ms\n",
      "video 1/1 (489/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 165.0ms\n",
      "video 1/1 (490/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.5ms\n",
      "video 1/1 (491/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.1ms\n",
      "video 1/1 (492/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.3ms\n",
      "video 1/1 (493/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.1ms\n",
      "video 1/1 (494/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 169.1ms\n",
      "video 1/1 (495/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.0ms\n",
      "video 1/1 (496/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 188.1ms\n",
      "video 1/1 (497/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 127.6ms\n",
      "video 1/1 (498/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 159.1ms\n",
      "video 1/1 (499/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 131.5ms\n",
      "video 1/1 (500/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 136.5ms\n",
      "video 1/1 (501/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 139.3ms\n",
      "video 1/1 (502/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 118.9ms\n",
      "video 1/1 (503/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 125.4ms\n",
      "video 1/1 (504/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 130.5ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (505/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 141.7ms\n",
      "video 1/1 (506/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 153.6ms\n",
      "video 1/1 (507/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.6ms\n",
      "video 1/1 (508/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 136.5ms\n",
      "video 1/1 (509/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.1ms\n",
      "video 1/1 (510/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.9ms\n",
      "video 1/1 (511/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 160.8ms\n",
      "video 1/1 (512/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.9ms\n",
      "video 1/1 (513/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.0ms\n",
      "video 1/1 (514/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 125.9ms\n",
      "video 1/1 (515/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.7ms\n",
      "video 1/1 (516/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.2ms\n",
      "video 1/1 (517/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 167.4ms\n",
      "video 1/1 (518/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 129.5ms\n",
      "video 1/1 (519/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.5ms\n",
      "video 1/1 (520/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 160.5ms\n",
      "video 1/1 (521/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.6ms\n",
      "video 1/1 (522/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 137.7ms\n",
      "video 1/1 (523/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 150.7ms\n",
      "video 1/1 (524/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 137.2ms\n",
      "video 1/1 (525/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 136.5ms\n",
      "video 1/1 (526/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.2ms\n",
      "video 1/1 (527/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.6ms\n",
      "video 1/1 (528/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 127.0ms\n",
      "video 1/1 (529/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 118.9ms\n",
      "video 1/1 (530/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 173.0ms\n",
      "video 1/1 (531/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 115.9ms\n",
      "video 1/1 (532/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 117.7ms\n",
      "video 1/1 (533/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 141.6ms\n",
      "video 1/1 (534/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 132.1ms\n",
      "video 1/1 (535/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 126.3ms\n",
      "video 1/1 (536/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 124.7ms\n",
      "video 1/1 (537/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 146.1ms\n",
      "video 1/1 (538/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 138.5ms\n",
      "video 1/1 (539/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.6ms\n",
      "video 1/1 (540/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.4ms\n",
      "video 1/1 (541/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.8ms\n",
      "video 1/1 (542/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 124.4ms\n",
      "video 1/1 (543/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 154.6ms\n",
      "video 1/1 (544/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 153.7ms\n",
      "video 1/1 (545/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 121.9ms\n",
      "video 1/1 (546/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 130.1ms\n",
      "video 1/1 (547/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.4ms\n",
      "video 1/1 (548/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 160.3ms\n",
      "video 1/1 (549/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 203.1ms\n",
      "video 1/1 (550/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 172.9ms\n",
      "video 1/1 (551/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 117.6ms\n",
      "video 1/1 (552/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 148.5ms\n",
      "video 1/1 (553/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.6ms\n",
      "video 1/1 (554/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.4ms\n",
      "video 1/1 (555/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 139.6ms\n",
      "video 1/1 (556/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 136.5ms\n",
      "video 1/1 (557/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.6ms\n",
      "video 1/1 (558/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 151.7ms\n",
      "video 1/1 (559/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 136.0ms\n",
      "video 1/1 (560/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.7ms\n",
      "video 1/1 (561/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.8ms\n",
      "video 1/1 (562/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 154.7ms\n",
      "video 1/1 (563/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.2ms\n",
      "video 1/1 (564/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.1ms\n",
      "video 1/1 (565/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.9ms\n",
      "video 1/1 (566/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 158.7ms\n",
      "video 1/1 (567/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.8ms\n",
      "video 1/1 (568/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.4ms\n",
      "video 1/1 (569/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 163.9ms\n",
      "video 1/1 (570/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 153.8ms\n",
      "video 1/1 (571/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 145.2ms\n",
      "video 1/1 (572/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Bad Sitting Pose, 132.3ms\n",
      "video 1/1 (573/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 166.9ms\n",
      "video 1/1 (574/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.5ms\n",
      "video 1/1 (575/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 148.3ms\n",
      "video 1/1 (576/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 159.2ms\n",
      "video 1/1 (577/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 148.1ms\n",
      "video 1/1 (578/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 170.4ms\n",
      "video 1/1 (579/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.3ms\n",
      "video 1/1 (580/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.7ms\n",
      "video 1/1 (581/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.8ms\n",
      "video 1/1 (582/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.8ms\n",
      "video 1/1 (583/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 147.9ms\n",
      "video 1/1 (584/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 147.7ms\n",
      "video 1/1 (585/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.3ms\n",
      "video 1/1 (586/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 154.9ms\n",
      "video 1/1 (587/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 162.1ms\n",
      "video 1/1 (588/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 136.9ms\n",
      "video 1/1 (589/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 133.5ms\n",
      "video 1/1 (590/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 160.5ms\n",
      "video 1/1 (591/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 161.5ms\n",
      "video 1/1 (592/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 161.0ms\n",
      "video 1/1 (593/740) D:\\Sitting pose\\s3.mp4: 640x384 (no detections), 119.7ms\n",
      "video 1/1 (594/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.4ms\n",
      "video 1/1 (595/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.7ms\n",
      "video 1/1 (596/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.8ms\n",
      "video 1/1 (597/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 144.1ms\n",
      "video 1/1 (598/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 159.3ms\n",
      "video 1/1 (599/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 139.1ms\n",
      "video 1/1 (600/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.0ms\n",
      "video 1/1 (601/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 146.7ms\n",
      "video 1/1 (602/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 167.3ms\n",
      "video 1/1 (603/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 135.7ms\n",
      "video 1/1 (604/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 169.9ms\n",
      "video 1/1 (605/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 174.8ms\n",
      "video 1/1 (606/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 164.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (607/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 165.3ms\n",
      "video 1/1 (608/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.8ms\n",
      "video 1/1 (609/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 147.3ms\n",
      "video 1/1 (610/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 163.6ms\n",
      "video 1/1 (611/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 165.1ms\n",
      "video 1/1 (612/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 150.6ms\n",
      "video 1/1 (613/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.4ms\n",
      "video 1/1 (614/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 166.1ms\n",
      "video 1/1 (615/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 143.9ms\n",
      "video 1/1 (616/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 128.9ms\n",
      "video 1/1 (617/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 168.7ms\n",
      "video 1/1 (618/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 191.8ms\n",
      "video 1/1 (619/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 155.5ms\n",
      "video 1/1 (620/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 132.2ms\n",
      "video 1/1 (621/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 126.9ms\n",
      "video 1/1 (622/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 132.7ms\n",
      "video 1/1 (623/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 137.7ms\n",
      "video 1/1 (624/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 200.8ms\n",
      "video 1/1 (625/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 131.3ms\n",
      "video 1/1 (626/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 149.6ms\n",
      "video 1/1 (627/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 125.2ms\n",
      "video 1/1 (628/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 128.0ms\n",
      "video 1/1 (629/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 139.0ms\n",
      "video 1/1 (630/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 131.7ms\n",
      "video 1/1 (631/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 145.4ms\n",
      "video 1/1 (632/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 144.5ms\n",
      "video 1/1 (633/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 153.7ms\n",
      "video 1/1 (634/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 124.5ms\n",
      "video 1/1 (635/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 148.8ms\n",
      "video 1/1 (636/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.3ms\n",
      "video 1/1 (637/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 152.8ms\n",
      "video 1/1 (638/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 157.2ms\n",
      "video 1/1 (639/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 161.7ms\n",
      "video 1/1 (640/740) D:\\Sitting pose\\s3.mp4: 640x384 1 Good Sitting Pose, 117.6ms\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 24883200 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBAPS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain6\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load a custom model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Predict with the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSitting pose\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms3.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\model.py:96\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\model.py:238\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:194\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\utils\\_contextlib.py:56\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 56\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\engine\\predictor.py:242\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch, profilers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, [], \u001b[38;5;28;01mNone\u001b[39;00m, (ops\u001b[38;5;241m.\u001b[39mProfile(), ops\u001b[38;5;241m.\u001b[39mProfile(), ops\u001b[38;5;241m.\u001b[39mProfile())\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_predict_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_predict_batch_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ultralytics\\data\\loaders.py:250\u001b[0m, in \u001b[0;36mLoadImages.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvid_stride):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[1;32m--> 250\u001b[0m success, im0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 24883200 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\pose\\train6\\weights\\best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(r'D:\\Sitting pose\\s3.mp4', save=True, conf=0.5)  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea8fed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 1296.1ms\n",
      "video 1/1 (2/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 395.2ms\n",
      "video 1/1 (3/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 101.7ms\n",
      "video 1/1 (4/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 115.5ms\n",
      "video 1/1 (5/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.3ms\n",
      "video 1/1 (6/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.1ms\n",
      "video 1/1 (7/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.9ms\n",
      "video 1/1 (8/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.3ms\n",
      "video 1/1 (9/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 151.7ms\n",
      "video 1/1 (10/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.0ms\n",
      "video 1/1 (11/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 162.5ms\n",
      "video 1/1 (12/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.5ms\n",
      "video 1/1 (13/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 136.8ms\n",
      "video 1/1 (14/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.7ms\n",
      "video 1/1 (15/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.8ms\n",
      "video 1/1 (16/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 174.0ms\n",
      "video 1/1 (17/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 162.5ms\n",
      "video 1/1 (18/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 154.5ms\n",
      "video 1/1 (19/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 135.7ms\n",
      "video 1/1 (20/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 147.5ms\n",
      "video 1/1 (21/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 143.8ms\n",
      "video 1/1 (22/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 124.9ms\n",
      "video 1/1 (23/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 144.6ms\n",
      "video 1/1 (24/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 151.7ms\n",
      "video 1/1 (25/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 178.5ms\n",
      "video 1/1 (26/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 147.3ms\n",
      "video 1/1 (27/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 287.6ms\n",
      "video 1/1 (28/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 142.4ms\n",
      "video 1/1 (29/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 131.6ms\n",
      "video 1/1 (30/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.8ms\n",
      "video 1/1 (31/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 140.5ms\n",
      "video 1/1 (32/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 165.1ms\n",
      "video 1/1 (33/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 167.1ms\n",
      "video 1/1 (34/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 142.3ms\n",
      "video 1/1 (35/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 156.7ms\n",
      "video 1/1 (36/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.4ms\n",
      "video 1/1 (37/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 135.1ms\n",
      "video 1/1 (38/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 125.4ms\n",
      "video 1/1 (39/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 122.3ms\n",
      "video 1/1 (40/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 146.3ms\n",
      "video 1/1 (41/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 133.1ms\n",
      "video 1/1 (42/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 125.2ms\n",
      "video 1/1 (43/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 142.8ms\n",
      "video 1/1 (44/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.6ms\n",
      "video 1/1 (45/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.6ms\n",
      "video 1/1 (46/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.9ms\n",
      "video 1/1 (47/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.7ms\n",
      "video 1/1 (48/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.8ms\n",
      "video 1/1 (49/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 129.5ms\n",
      "video 1/1 (50/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.7ms\n",
      "video 1/1 (51/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.0ms\n",
      "video 1/1 (52/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 123.4ms\n",
      "video 1/1 (53/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.0ms\n",
      "video 1/1 (54/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 143.8ms\n",
      "video 1/1 (55/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.1ms\n",
      "video 1/1 (56/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.6ms\n",
      "video 1/1 (57/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.1ms\n",
      "video 1/1 (58/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 162.2ms\n",
      "video 1/1 (59/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.5ms\n",
      "video 1/1 (60/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 137.1ms\n",
      "video 1/1 (61/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.2ms\n",
      "video 1/1 (62/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.7ms\n",
      "video 1/1 (63/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.8ms\n",
      "video 1/1 (64/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 127.2ms\n",
      "video 1/1 (65/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 139.0ms\n",
      "video 1/1 (66/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.1ms\n",
      "video 1/1 (67/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.5ms\n",
      "video 1/1 (68/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.1ms\n",
      "video 1/1 (69/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.7ms\n",
      "video 1/1 (70/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.3ms\n",
      "video 1/1 (71/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.9ms\n",
      "video 1/1 (72/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.8ms\n",
      "video 1/1 (73/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 143.5ms\n",
      "video 1/1 (74/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 161.0ms\n",
      "video 1/1 (75/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.3ms\n",
      "video 1/1 (76/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.1ms\n",
      "video 1/1 (77/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.8ms\n",
      "video 1/1 (78/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 214.7ms\n",
      "video 1/1 (79/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.6ms\n",
      "video 1/1 (80/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.0ms\n",
      "video 1/1 (81/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.7ms\n",
      "video 1/1 (82/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.0ms\n",
      "video 1/1 (83/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.1ms\n",
      "video 1/1 (84/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 162.6ms\n",
      "video 1/1 (85/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.7ms\n",
      "video 1/1 (86/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 189.5ms\n",
      "video 1/1 (87/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.1ms\n",
      "video 1/1 (88/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 142.4ms\n",
      "video 1/1 (89/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.4ms\n",
      "video 1/1 (90/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.2ms\n",
      "video 1/1 (91/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.6ms\n",
      "video 1/1 (92/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.9ms\n",
      "video 1/1 (93/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.0ms\n",
      "video 1/1 (94/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.5ms\n",
      "video 1/1 (95/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.7ms\n",
      "video 1/1 (96/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.6ms\n",
      "video 1/1 (97/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.6ms\n",
      "video 1/1 (98/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 185.1ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (99/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.5ms\n",
      "video 1/1 (100/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.7ms\n",
      "video 1/1 (101/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.3ms\n",
      "video 1/1 (102/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.5ms\n",
      "video 1/1 (103/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.9ms\n",
      "video 1/1 (104/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.6ms\n",
      "video 1/1 (105/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 207.7ms\n",
      "video 1/1 (106/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 142.2ms\n",
      "video 1/1 (107/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 139.0ms\n",
      "video 1/1 (108/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.8ms\n",
      "video 1/1 (109/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 276.0ms\n",
      "video 1/1 (110/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.6ms\n",
      "video 1/1 (111/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.2ms\n",
      "video 1/1 (112/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.0ms\n",
      "video 1/1 (113/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.7ms\n",
      "video 1/1 (114/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.9ms\n",
      "video 1/1 (115/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.6ms\n",
      "video 1/1 (116/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.4ms\n",
      "video 1/1 (117/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.9ms\n",
      "video 1/1 (118/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.3ms\n",
      "video 1/1 (119/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.2ms\n",
      "video 1/1 (120/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.3ms\n",
      "video 1/1 (121/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.2ms\n",
      "video 1/1 (122/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.0ms\n",
      "video 1/1 (123/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.8ms\n",
      "video 1/1 (124/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.8ms\n",
      "video 1/1 (125/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.6ms\n",
      "video 1/1 (126/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 188.8ms\n",
      "video 1/1 (127/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 192.7ms\n",
      "video 1/1 (128/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.4ms\n",
      "video 1/1 (129/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.5ms\n",
      "video 1/1 (130/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.8ms\n",
      "video 1/1 (131/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.9ms\n",
      "video 1/1 (132/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.5ms\n",
      "video 1/1 (133/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.0ms\n",
      "video 1/1 (134/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.9ms\n",
      "video 1/1 (135/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.5ms\n",
      "video 1/1 (136/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 203.8ms\n",
      "video 1/1 (137/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.4ms\n",
      "video 1/1 (138/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.0ms\n",
      "video 1/1 (139/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.7ms\n",
      "video 1/1 (140/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 187.7ms\n",
      "video 1/1 (141/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.6ms\n",
      "video 1/1 (142/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 191.8ms\n",
      "video 1/1 (143/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.4ms\n",
      "video 1/1 (144/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.9ms\n",
      "video 1/1 (145/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 267.2ms\n",
      "video 1/1 (146/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 189.8ms\n",
      "video 1/1 (147/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.1ms\n",
      "video 1/1 (148/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.6ms\n",
      "video 1/1 (149/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 188.0ms\n",
      "video 1/1 (150/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 188.7ms\n",
      "video 1/1 (151/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.3ms\n",
      "video 1/1 (152/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.0ms\n",
      "video 1/1 (153/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 187.6ms\n",
      "video 1/1 (154/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.9ms\n",
      "video 1/1 (155/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.7ms\n",
      "video 1/1 (156/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.5ms\n",
      "video 1/1 (157/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 188.8ms\n",
      "video 1/1 (158/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.5ms\n",
      "video 1/1 (159/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.5ms\n",
      "video 1/1 (160/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.9ms\n",
      "video 1/1 (161/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.4ms\n",
      "video 1/1 (162/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.4ms\n",
      "video 1/1 (163/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 182.1ms\n",
      "video 1/1 (164/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.3ms\n",
      "video 1/1 (165/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 186.1ms\n",
      "video 1/1 (166/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.2ms\n",
      "video 1/1 (167/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 190.7ms\n",
      "video 1/1 (168/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 132.0ms\n",
      "video 1/1 (169/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.5ms\n",
      "video 1/1 (170/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.9ms\n",
      "video 1/1 (171/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.5ms\n",
      "video 1/1 (172/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.5ms\n",
      "video 1/1 (173/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.4ms\n",
      "video 1/1 (174/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.6ms\n",
      "video 1/1 (175/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 143.5ms\n",
      "video 1/1 (176/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.5ms\n",
      "video 1/1 (177/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.7ms\n",
      "video 1/1 (178/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 158.1ms\n",
      "video 1/1 (179/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.6ms\n",
      "video 1/1 (180/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.0ms\n",
      "video 1/1 (181/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.8ms\n",
      "video 1/1 (182/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.5ms\n",
      "video 1/1 (183/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.6ms\n",
      "video 1/1 (184/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 158.3ms\n",
      "video 1/1 (185/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 172.3ms\n",
      "video 1/1 (186/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 137.9ms\n",
      "video 1/1 (187/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 140.2ms\n",
      "video 1/1 (188/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.4ms\n",
      "video 1/1 (189/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.8ms\n",
      "video 1/1 (190/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.6ms\n",
      "video 1/1 (191/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.2ms\n",
      "video 1/1 (192/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.6ms\n",
      "video 1/1 (193/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 173.2ms\n",
      "video 1/1 (194/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.5ms\n",
      "video 1/1 (195/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.3ms\n",
      "video 1/1 (196/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.7ms\n",
      "video 1/1 (197/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.3ms\n",
      "video 1/1 (198/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.4ms\n",
      "video 1/1 (199/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 164.7ms\n",
      "video 1/1 (200/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 142.9ms\n",
      "video 1/1 (201/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 181.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (202/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.3ms\n",
      "video 1/1 (203/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.9ms\n",
      "video 1/1 (204/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.7ms\n",
      "video 1/1 (205/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 173.7ms\n",
      "video 1/1 (206/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 157.4ms\n",
      "video 1/1 (207/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.7ms\n",
      "video 1/1 (208/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.0ms\n",
      "video 1/1 (209/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.2ms\n",
      "video 1/1 (210/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 141.9ms\n",
      "video 1/1 (211/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.3ms\n",
      "video 1/1 (212/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.6ms\n",
      "video 1/1 (213/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.8ms\n",
      "video 1/1 (214/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 135.8ms\n",
      "video 1/1 (215/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.6ms\n",
      "video 1/1 (216/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.5ms\n",
      "video 1/1 (217/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.6ms\n",
      "video 1/1 (218/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.4ms\n",
      "video 1/1 (219/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 131.8ms\n",
      "video 1/1 (220/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 243.4ms\n",
      "video 1/1 (221/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.4ms\n",
      "video 1/1 (222/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 257.2ms\n",
      "video 1/1 (223/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 130.1ms\n",
      "video 1/1 (224/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 133.1ms\n",
      "video 1/1 (225/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 133.5ms\n",
      "video 1/1 (226/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.2ms\n",
      "video 1/1 (227/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.9ms\n",
      "video 1/1 (228/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.5ms\n",
      "video 1/1 (229/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.0ms\n",
      "video 1/1 (230/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 135.8ms\n",
      "video 1/1 (231/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 134.8ms\n",
      "video 1/1 (232/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.9ms\n",
      "video 1/1 (233/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 143.0ms\n",
      "video 1/1 (234/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.3ms\n",
      "video 1/1 (235/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.7ms\n",
      "video 1/1 (236/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 132.6ms\n",
      "video 1/1 (237/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 128.2ms\n",
      "video 1/1 (238/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 151.7ms\n",
      "video 1/1 (239/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 134.4ms\n",
      "video 1/1 (240/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 146.7ms\n",
      "video 1/1 (241/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 132.4ms\n",
      "video 1/1 (242/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 112.0ms\n",
      "video 1/1 (243/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 136.9ms\n",
      "video 1/1 (244/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.1ms\n",
      "video 1/1 (245/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 146.6ms\n",
      "video 1/1 (246/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 135.1ms\n",
      "video 1/1 (247/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 128.2ms\n",
      "video 1/1 (248/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 117.3ms\n",
      "video 1/1 (249/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 142.8ms\n",
      "video 1/1 (250/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.7ms\n",
      "video 1/1 (251/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.8ms\n",
      "video 1/1 (252/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 146.6ms\n",
      "video 1/1 (253/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.3ms\n",
      "video 1/1 (254/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.7ms\n",
      "video 1/1 (255/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 134.8ms\n",
      "video 1/1 (256/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.2ms\n",
      "video 1/1 (257/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.9ms\n",
      "video 1/1 (258/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.1ms\n",
      "video 1/1 (259/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.5ms\n",
      "video 1/1 (260/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 144.2ms\n",
      "video 1/1 (261/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.3ms\n",
      "video 1/1 (262/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.8ms\n",
      "video 1/1 (263/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.6ms\n",
      "video 1/1 (264/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.1ms\n",
      "video 1/1 (265/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.2ms\n",
      "video 1/1 (266/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.6ms\n",
      "video 1/1 (267/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.7ms\n",
      "video 1/1 (268/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.7ms\n",
      "video 1/1 (269/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.1ms\n",
      "video 1/1 (270/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.4ms\n",
      "video 1/1 (271/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.4ms\n",
      "video 1/1 (272/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.6ms\n",
      "video 1/1 (273/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 181.1ms\n",
      "video 1/1 (274/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.0ms\n",
      "video 1/1 (275/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.8ms\n",
      "video 1/1 (276/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.8ms\n",
      "video 1/1 (277/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.1ms\n",
      "video 1/1 (278/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.4ms\n",
      "video 1/1 (279/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 142.0ms\n",
      "video 1/1 (280/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.0ms\n",
      "video 1/1 (281/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.1ms\n",
      "video 1/1 (282/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 128.8ms\n",
      "video 1/1 (283/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.5ms\n",
      "video 1/1 (284/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.1ms\n",
      "video 1/1 (285/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.1ms\n",
      "video 1/1 (286/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 200.2ms\n",
      "video 1/1 (287/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 139.8ms\n",
      "video 1/1 (288/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.5ms\n",
      "video 1/1 (289/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.2ms\n",
      "video 1/1 (290/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.0ms\n",
      "video 1/1 (291/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.2ms\n",
      "video 1/1 (292/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.2ms\n",
      "video 1/1 (293/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.7ms\n",
      "video 1/1 (294/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.8ms\n",
      "video 1/1 (295/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.5ms\n",
      "video 1/1 (296/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.5ms\n",
      "video 1/1 (297/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 187.5ms\n",
      "video 1/1 (298/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.6ms\n",
      "video 1/1 (299/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.7ms\n",
      "video 1/1 (300/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.8ms\n",
      "video 1/1 (301/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.3ms\n",
      "video 1/1 (302/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.4ms\n",
      "video 1/1 (303/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.4ms\n",
      "video 1/1 (304/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (305/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 181.5ms\n",
      "video 1/1 (306/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.2ms\n",
      "video 1/1 (307/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 158.4ms\n",
      "video 1/1 (308/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.4ms\n",
      "video 1/1 (309/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.7ms\n",
      "video 1/1 (310/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.8ms\n",
      "video 1/1 (311/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.6ms\n",
      "video 1/1 (312/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.8ms\n",
      "video 1/1 (313/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.2ms\n",
      "video 1/1 (314/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.1ms\n",
      "video 1/1 (315/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 182.2ms\n",
      "video 1/1 (316/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.9ms\n",
      "video 1/1 (317/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 178.2ms\n",
      "video 1/1 (318/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.4ms\n",
      "video 1/1 (319/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.7ms\n",
      "video 1/1 (320/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.9ms\n",
      "video 1/1 (321/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.2ms\n",
      "video 1/1 (322/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.3ms\n",
      "video 1/1 (323/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.3ms\n",
      "video 1/1 (324/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.1ms\n",
      "video 1/1 (325/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 187.0ms\n",
      "video 1/1 (326/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.2ms\n",
      "video 1/1 (327/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.2ms\n",
      "video 1/1 (328/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 213.9ms\n",
      "video 1/1 (329/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.4ms\n",
      "video 1/1 (330/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.5ms\n",
      "video 1/1 (331/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.9ms\n",
      "video 1/1 (332/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.2ms\n",
      "video 1/1 (333/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.4ms\n",
      "video 1/1 (334/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 146.7ms\n",
      "video 1/1 (335/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.6ms\n",
      "video 1/1 (336/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 152.7ms\n",
      "video 1/1 (337/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.4ms\n",
      "video 1/1 (338/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.8ms\n",
      "video 1/1 (339/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.5ms\n",
      "video 1/1 (340/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.6ms\n",
      "video 1/1 (341/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 135.6ms\n",
      "video 1/1 (342/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.2ms\n",
      "video 1/1 (343/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.7ms\n",
      "video 1/1 (344/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.2ms\n",
      "video 1/1 (345/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.9ms\n",
      "video 1/1 (346/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 344.2ms\n",
      "video 1/1 (347/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.7ms\n",
      "video 1/1 (348/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.8ms\n",
      "video 1/1 (349/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.7ms\n",
      "video 1/1 (350/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.5ms\n",
      "video 1/1 (351/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 164.9ms\n",
      "video 1/1 (352/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.4ms\n",
      "video 1/1 (353/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.1ms\n",
      "video 1/1 (354/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.6ms\n",
      "video 1/1 (355/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.5ms\n",
      "video 1/1 (356/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.8ms\n",
      "video 1/1 (357/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.9ms\n",
      "video 1/1 (358/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 177.7ms\n",
      "video 1/1 (359/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 173.1ms\n",
      "video 1/1 (360/626) D:\\Sitting pose\\s2.mp4: 384x640 2 Bad Sitting Poses, 169.8ms\n",
      "video 1/1 (361/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 181.7ms\n",
      "video 1/1 (362/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.9ms\n",
      "video 1/1 (363/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.1ms\n",
      "video 1/1 (364/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.5ms\n",
      "video 1/1 (365/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 137.1ms\n",
      "video 1/1 (366/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 185.0ms\n",
      "video 1/1 (367/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.7ms\n",
      "video 1/1 (368/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 209.6ms\n",
      "video 1/1 (369/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 154.7ms\n",
      "video 1/1 (370/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.5ms\n",
      "video 1/1 (371/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.4ms\n",
      "video 1/1 (372/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 152.3ms\n",
      "video 1/1 (373/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.0ms\n",
      "video 1/1 (374/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.8ms\n",
      "video 1/1 (375/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.2ms\n",
      "video 1/1 (376/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 173.3ms\n",
      "video 1/1 (377/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.8ms\n",
      "video 1/1 (378/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.8ms\n",
      "video 1/1 (379/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.9ms\n",
      "video 1/1 (380/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 151.2ms\n",
      "video 1/1 (381/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 156.3ms\n",
      "video 1/1 (382/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 155.0ms\n",
      "video 1/1 (383/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 137.4ms\n",
      "video 1/1 (384/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 126.6ms\n",
      "video 1/1 (385/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 128.6ms\n",
      "video 1/1 (386/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 134.2ms\n",
      "video 1/1 (387/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 127.8ms\n",
      "video 1/1 (388/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 123.1ms\n",
      "video 1/1 (389/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 139.2ms\n",
      "video 1/1 (390/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 121.0ms\n",
      "video 1/1 (391/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 129.3ms\n",
      "video 1/1 (392/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.2ms\n",
      "video 1/1 (393/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.1ms\n",
      "video 1/1 (394/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 137.1ms\n",
      "video 1/1 (395/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.6ms\n",
      "video 1/1 (396/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 134.2ms\n",
      "video 1/1 (397/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.2ms\n",
      "video 1/1 (398/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 122.5ms\n",
      "video 1/1 (399/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 126.0ms\n",
      "video 1/1 (400/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 133.8ms\n",
      "video 1/1 (401/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 131.0ms\n",
      "video 1/1 (402/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 134.4ms\n",
      "video 1/1 (403/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.1ms\n",
      "video 1/1 (404/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.2ms\n",
      "video 1/1 (405/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.2ms\n",
      "video 1/1 (406/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 138.2ms\n",
      "video 1/1 (407/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 137.5ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (408/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 140.5ms\n",
      "video 1/1 (409/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 124.3ms\n",
      "video 1/1 (410/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 132.8ms\n",
      "video 1/1 (411/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 147.8ms\n",
      "video 1/1 (412/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.2ms\n",
      "video 1/1 (413/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.3ms\n",
      "video 1/1 (414/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.0ms\n",
      "video 1/1 (415/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.8ms\n",
      "video 1/1 (416/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.3ms\n",
      "video 1/1 (417/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.4ms\n",
      "video 1/1 (418/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 144.3ms\n",
      "video 1/1 (419/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.8ms\n",
      "video 1/1 (420/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.5ms\n",
      "video 1/1 (421/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.9ms\n",
      "video 1/1 (422/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 158.7ms\n",
      "video 1/1 (423/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.6ms\n",
      "video 1/1 (424/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.3ms\n",
      "video 1/1 (425/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.6ms\n",
      "video 1/1 (426/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.1ms\n",
      "video 1/1 (427/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 184.7ms\n",
      "video 1/1 (428/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.2ms\n",
      "video 1/1 (429/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 186.6ms\n",
      "video 1/1 (430/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.5ms\n",
      "video 1/1 (431/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.4ms\n",
      "video 1/1 (432/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 137.9ms\n",
      "video 1/1 (433/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.9ms\n",
      "video 1/1 (434/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 184.7ms\n",
      "video 1/1 (435/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.6ms\n",
      "video 1/1 (436/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 146.6ms\n",
      "video 1/1 (437/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.4ms\n",
      "video 1/1 (438/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.7ms\n",
      "video 1/1 (439/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 158.3ms\n",
      "video 1/1 (440/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 152.3ms\n",
      "video 1/1 (441/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 221.2ms\n",
      "video 1/1 (442/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.0ms\n",
      "video 1/1 (443/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.8ms\n",
      "video 1/1 (444/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.8ms\n",
      "video 1/1 (445/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.4ms\n",
      "video 1/1 (446/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 167.1ms\n",
      "video 1/1 (447/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 208.4ms\n",
      "video 1/1 (448/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.9ms\n",
      "video 1/1 (449/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.7ms\n",
      "video 1/1 (450/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 149.4ms\n",
      "video 1/1 (451/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.0ms\n",
      "video 1/1 (452/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.4ms\n",
      "video 1/1 (453/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 145.6ms\n",
      "video 1/1 (454/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.4ms\n",
      "video 1/1 (455/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.1ms\n",
      "video 1/1 (456/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.7ms\n",
      "video 1/1 (457/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.7ms\n",
      "video 1/1 (458/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.0ms\n",
      "video 1/1 (459/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.5ms\n",
      "video 1/1 (460/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.4ms\n",
      "video 1/1 (461/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.4ms\n",
      "video 1/1 (462/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.4ms\n",
      "video 1/1 (463/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.6ms\n",
      "video 1/1 (464/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.2ms\n",
      "video 1/1 (465/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.9ms\n",
      "video 1/1 (466/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.4ms\n",
      "video 1/1 (467/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.4ms\n",
      "video 1/1 (468/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.7ms\n",
      "video 1/1 (469/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.2ms\n",
      "video 1/1 (470/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.3ms\n",
      "video 1/1 (471/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.2ms\n",
      "video 1/1 (472/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.6ms\n",
      "video 1/1 (473/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.7ms\n",
      "video 1/1 (474/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.1ms\n",
      "video 1/1 (475/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.8ms\n",
      "video 1/1 (476/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.6ms\n",
      "video 1/1 (477/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.9ms\n",
      "video 1/1 (478/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.3ms\n",
      "video 1/1 (479/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.9ms\n",
      "video 1/1 (480/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.7ms\n",
      "video 1/1 (481/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 165.7ms\n",
      "video 1/1 (482/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.7ms\n",
      "video 1/1 (483/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.3ms\n",
      "video 1/1 (484/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.2ms\n",
      "video 1/1 (485/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.8ms\n",
      "video 1/1 (486/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.3ms\n",
      "video 1/1 (487/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 162.7ms\n",
      "video 1/1 (488/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.8ms\n",
      "video 1/1 (489/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.0ms\n",
      "video 1/1 (490/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.0ms\n",
      "video 1/1 (491/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.5ms\n",
      "video 1/1 (492/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.0ms\n",
      "video 1/1 (493/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.0ms\n",
      "video 1/1 (494/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.3ms\n",
      "video 1/1 (495/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.1ms\n",
      "video 1/1 (496/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 169.0ms\n",
      "video 1/1 (497/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.7ms\n",
      "video 1/1 (498/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 150.6ms\n",
      "video 1/1 (499/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 155.9ms\n",
      "video 1/1 (500/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.4ms\n",
      "video 1/1 (501/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 175.7ms\n",
      "video 1/1 (502/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.8ms\n",
      "video 1/1 (503/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.2ms\n",
      "video 1/1 (504/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 172.1ms\n",
      "video 1/1 (505/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 171.9ms\n",
      "video 1/1 (506/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 165.7ms\n",
      "video 1/1 (507/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 170.5ms\n",
      "video 1/1 (508/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 167.1ms\n",
      "video 1/1 (509/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 170.0ms\n",
      "video 1/1 (510/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 166.4ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (511/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 171.5ms\n",
      "video 1/1 (512/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 175.1ms\n",
      "video 1/1 (513/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 180.3ms\n",
      "video 1/1 (514/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 179.6ms\n",
      "video 1/1 (515/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 164.4ms\n",
      "video 1/1 (516/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 180.3ms\n",
      "video 1/1 (517/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 180.4ms\n",
      "video 1/1 (518/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 172.6ms\n",
      "video 1/1 (519/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 153.8ms\n",
      "video 1/1 (520/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 154.3ms\n",
      "video 1/1 (521/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 179.4ms\n",
      "video 1/1 (522/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 179.3ms\n",
      "video 1/1 (523/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.6ms\n",
      "video 1/1 (524/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 178.5ms\n",
      "video 1/1 (525/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.9ms\n",
      "video 1/1 (526/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.0ms\n",
      "video 1/1 (527/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.0ms\n",
      "video 1/1 (528/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.1ms\n",
      "video 1/1 (529/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 172.4ms\n",
      "video 1/1 (530/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 170.7ms\n",
      "video 1/1 (531/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.7ms\n",
      "video 1/1 (532/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 171.2ms\n",
      "video 1/1 (533/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.0ms\n",
      "video 1/1 (534/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.2ms\n",
      "video 1/1 (535/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.5ms\n",
      "video 1/1 (536/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 173.9ms\n",
      "video 1/1 (537/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 161.3ms\n",
      "video 1/1 (538/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 172.8ms\n",
      "video 1/1 (539/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 158.6ms\n",
      "video 1/1 (540/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 167.0ms\n",
      "video 1/1 (541/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 164.6ms\n",
      "video 1/1 (542/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 187.4ms\n",
      "video 1/1 (543/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.3ms\n",
      "video 1/1 (544/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 156.1ms\n",
      "video 1/1 (545/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 148.8ms\n",
      "video 1/1 (546/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.3ms\n",
      "video 1/1 (547/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.3ms\n",
      "video 1/1 (548/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.0ms\n",
      "video 1/1 (549/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.4ms\n",
      "video 1/1 (550/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.8ms\n",
      "video 1/1 (551/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 164.5ms\n",
      "video 1/1 (552/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 180.9ms\n",
      "video 1/1 (553/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 122.0ms\n",
      "video 1/1 (554/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 169.3ms\n",
      "video 1/1 (555/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 161.7ms\n",
      "video 1/1 (556/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 142.7ms\n",
      "video 1/1 (557/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 131.4ms\n",
      "video 1/1 (558/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 177.3ms\n",
      "video 1/1 (559/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.6ms\n",
      "video 1/1 (560/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.3ms\n",
      "video 1/1 (561/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 167.2ms\n",
      "video 1/1 (562/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.9ms\n",
      "video 1/1 (563/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 173.2ms\n",
      "video 1/1 (564/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 175.8ms\n",
      "video 1/1 (565/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 175.8ms\n",
      "video 1/1 (566/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.4ms\n",
      "video 1/1 (567/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 174.5ms\n",
      "video 1/1 (568/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.8ms\n",
      "video 1/1 (569/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.9ms\n",
      "video 1/1 (570/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.9ms\n",
      "video 1/1 (571/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.7ms\n",
      "video 1/1 (572/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 170.2ms\n",
      "video 1/1 (573/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 170.8ms\n",
      "video 1/1 (574/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 191.4ms\n",
      "video 1/1 (575/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Good Sitting Pose, 1 Bad Sitting Pose, 175.8ms\n",
      "video 1/1 (576/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 181.7ms\n",
      "video 1/1 (577/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.5ms\n",
      "video 1/1 (578/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 184.8ms\n",
      "video 1/1 (579/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.7ms\n",
      "video 1/1 (580/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.2ms\n",
      "video 1/1 (581/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.8ms\n",
      "video 1/1 (582/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 141.7ms\n",
      "video 1/1 (583/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.1ms\n",
      "video 1/1 (584/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 166.6ms\n",
      "video 1/1 (585/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.1ms\n",
      "video 1/1 (586/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 150.6ms\n",
      "video 1/1 (587/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.5ms\n",
      "video 1/1 (588/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 184.1ms\n",
      "video 1/1 (589/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.7ms\n",
      "video 1/1 (590/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 161.5ms\n",
      "video 1/1 (591/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 182.6ms\n",
      "video 1/1 (592/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 182.2ms\n",
      "video 1/1 (593/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 183.3ms\n",
      "video 1/1 (594/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.3ms\n",
      "video 1/1 (595/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 163.1ms\n",
      "video 1/1 (596/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 178.3ms\n",
      "video 1/1 (597/626) D:\\Sitting pose\\s2.mp4: 384x640 (no detections), 180.4ms\n",
      "video 1/1 (598/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 184.0ms\n",
      "video 1/1 (599/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.4ms\n",
      "video 1/1 (600/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 179.1ms\n",
      "video 1/1 (601/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.6ms\n",
      "video 1/1 (602/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 187.8ms\n",
      "video 1/1 (603/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 182.7ms\n",
      "video 1/1 (604/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 144.6ms\n",
      "video 1/1 (605/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.5ms\n",
      "video 1/1 (606/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.5ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video 1/1 (607/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.5ms\n",
      "video 1/1 (608/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.7ms\n",
      "video 1/1 (609/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.7ms\n",
      "video 1/1 (610/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 160.7ms\n",
      "video 1/1 (611/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.5ms\n",
      "video 1/1 (612/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 176.6ms\n",
      "video 1/1 (613/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 157.0ms\n",
      "video 1/1 (614/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 177.7ms\n",
      "video 1/1 (615/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 153.5ms\n",
      "video 1/1 (616/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 155.4ms\n",
      "video 1/1 (617/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 159.7ms\n",
      "video 1/1 (618/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 168.6ms\n",
      "video 1/1 (619/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 169.2ms\n",
      "video 1/1 (620/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 175.6ms\n",
      "video 1/1 (621/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 163.4ms\n",
      "video 1/1 (622/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 152.7ms\n",
      "video 1/1 (623/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.8ms\n",
      "video 1/1 (624/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 180.7ms\n",
      "video 1/1 (625/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 173.2ms\n",
      "video 1/1 (626/626) D:\\Sitting pose\\s2.mp4: 384x640 1 Bad Sitting Pose, 192.2ms\n",
      "Speed: 8.0ms preprocess, 165.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\BAPS\\runs\\pose\\predict6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.pt')  # load an official model\n",
    "model = YOLO(r'C:\\Users\\BAPS\\runs\\pose\\train6\\weights\\best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model(r'D:\\Sitting pose\\s2.mp4', save=True, conf=0.5)  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5829dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
